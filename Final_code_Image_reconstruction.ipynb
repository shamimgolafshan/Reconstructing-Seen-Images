{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGHlHDhkOScz"
      },
      "source": [
        "# **1. Install and Import packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFeZQb1bITdS",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#install bdpy for loading fMRI data\n",
        "!pip install bdpy\n",
        "!pip install SSIM-PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF9FGrWy2YN6"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import datetime\n",
        "import io\n",
        "import os\n",
        "import h5py\n",
        "import bdpy\n",
        "import time\n",
        "import torch\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import csv\n",
        "from sklearn.metrics import jaccard_score\n",
        "import matplotlib.pyplot as plt # plotting library\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg_kFEzov8P_"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUD5-14Oa6k"
      },
      "source": [
        "# **2. Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrF7o2VaKdNh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmKwQ3nIOnZA"
      },
      "source": [
        "# **3. Load fMRI Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwa9U2M0nmW8"
      },
      "outputs": [],
      "source": [
        "#load Training fMRI data h5 using bdpy\n",
        "\n",
        "full_training_data = bdpy.BData(r'C:\\Users\\Administrator\\Desktop\\Untitled Folder\\data\\fmri\\sub-02_perceptionNaturalImageTraining_original_VC.h5')\n",
        "#v1_train_fmri = full_training_data.select('ROI_V1')\n",
        "#train_fmri = v1_train_fmri\n",
        "stimulusID = full_training_data.select('stimulus_id')[0:6000]\n",
        "train_hvc = full_training_data.select('ROI_LOC + ROI_FFA + ROI_PPA')[0:6000]\n",
        "train_lvc = full_training_data.select('ROI_V1 + ROI_V2 + ROI_V3')[0:6000]\n",
        "fmri_train_v1 = full_training_data.select('ROI_V1')[0:6000]\n",
        "fmri_train_v2 = full_training_data.select('ROI_V2')[0:6000]\n",
        "fmri_train_v3 = full_training_data.select('ROI_V3')[0:6000]\n",
        "#full_training_data.show_metadata()\n",
        "#stimulusID = full_training_data.select('stimulus_id')[0:1200]\n",
        "#index = np.where(stimulusID == 3790512.014883)\n",
        "#print(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8PagSWJm2aW"
      },
      "outputs": [],
      "source": [
        "fmri_train_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ38BxGFWi44"
      },
      "outputs": [],
      "source": [
        "#load test fMRI dataset using bdpy\n",
        "\n",
        "full_testing_data = bdpy.BData(r'C:\\Users\\Administrator\\Desktop\\Untitled Folder\\data\\fmri\\sub-02_perceptionNaturalImageTest_original_VC.h5')\n",
        "#v1_test_fmri = full_testing_data.select('ROI_V1')[0:50]\n",
        "#test_fmri = v1_test_fmri\n",
        "test_hvc = full_testing_data.select('ROI_LOC + ROI_FFA + ROI_PPA')[0:50]\n",
        "test_lvc = full_testing_data.select('ROI_V1 + ROI_V2 + ROI_V3')[0:50]\n",
        "fmri_test_v1 = full_testing_data.select('ROI_V1')[0:50]\n",
        "fmri_test_v2 = full_testing_data.select('ROI_V2')[0:50]\n",
        "fmri_test_v3 = full_testing_data.select('ROI_V3')[0:50]\n",
        "stimulusID_test = full_testing_data.select('stimulus_id')[0:50]\n",
        "#test_fmri =full_testing_data.get()[0:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJKdncjfHrHR"
      },
      "source": [
        "# **Normalizing fMRI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypJf0jPzL2na"
      },
      "source": [
        "Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Y47ksSJPlq"
      },
      "outputs": [],
      "source": [
        "#Z score normalization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "for i in range(6000):\n",
        "  train_hvc[i] = stats.zscore(train_hvc[i])\n",
        "  train_lvc[i] = stats.zscore(train_lvc[i])\n",
        "  fmri_train_v1[i] = stats.zscore(fmri_train_v1[i])\n",
        "  fmri_train_v2[i] = stats.zscore(fmri_train_v2[i])\n",
        "  fmri_train_v3[i] = stats.zscore(fmri_train_v3[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHD-b1cWHxZk"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "for i in range(6000):\n",
        "  train_hvc[i] = train_hvc[i]/train_hvc[i].max()\n",
        "  train_lvc[i] = train_lvc[i]/train_lvc[i].max()\n",
        "  fmri_train_v1[i] = fmri_train_v1[i]/fmri_train_v1[i].max()\n",
        "  fmri_train_v2[i] = fmri_train_v2[i]/fmri_train_v2[i].max()\n",
        "  fmri_train_v3[i] = fmri_train_v3[i]/fmri_train_v3[i].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1TO2f5-LzQM"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcC9-EbsSGcn"
      },
      "outputs": [],
      "source": [
        "#Z score normalization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "for i in range(50):\n",
        "  test_hvc[i] = stats.zscore(test_hvc[i])\n",
        "  test_lvc[i] = stats.zscore(test_lvc[i])\n",
        "  fmri_test_v1[i] = stats.zscore(fmri_test_v1[i])\n",
        "  fmri_test_v2[i] = stats.zscore(fmri_test_v2[i])\n",
        "  fmri_test_v3[i] = stats.zscore(fmri_test_v3[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQzDUdS0SSaD"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "for i in range(50):\n",
        "  test_hvc[i] = test_hvc[i]/test_hvc[i].max()\n",
        "  test_lvc[i] = test_lvc[i]/test_lvc[i].max()\n",
        "  fmri_test_v1[i] = fmri_test_v1[i]/fmri_test_v1[i].max()\n",
        "  fmri_test_v2[i] = fmri_test_v2[i]/fmri_test_v2[i].max()\n",
        "  fmri_test_v3[i] = fmri_test_v3[i]/fmri_test_v3[i].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqc0Cxr0adxr"
      },
      "source": [
        "# **4. Train SM Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Japv0c_6F7_y"
      },
      "outputs": [],
      "source": [
        "#train_sm_decoder\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "n_epochs = 200 #100 bood\n",
        "batch_size = 50\n",
        "lr =  0.002# 0.0002\n",
        "b1 = 0.9\n",
        "b2 = 0.999\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "#%cd /content/drive/My\\ Drive/thesis/data/fMRI_data/demo1/\n",
        "#full_training_data = bdpy.BData('sub-01_perceptionNaturalImageTraining_original_VC.h5')\n",
        "#full_testing_data = bdpy.BData('sub-01_perceptionNaturalImageTest_original_VC.h5')\n",
        "train_fmri = train_hvc\n",
        "test_fmri = test_hvc\n",
        "fmri = np.concatenate([train_fmri, test_fmri])\n",
        "#fmri = torch.load('../data/fMRI_data/demo1/digits-fmri')\n",
        "\n",
        "#lables of training data\n",
        "# %cd /content\n",
        "train_labels = []\n",
        "\n",
        "# \"convert tsv file into dictioary\"\n",
        "tsv_file = open(r\"C:\\Users\\Administrator\\Desktop\\Untitled Folder\\data\\tsv\\stimulus_NaturalImageTraining.tsv\")\n",
        "read_tsv = csv. reader(tsv_file, delimiter=\"\\t\")\n",
        "df = pd.DataFrame(read_tsv)\n",
        "df = df.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "for i in range(0,6000):\n",
        "  m = df['label'][df['ID'] == str(stimulusID[i][0])]\n",
        "  train_labels.append(int(m)-1)\n",
        "\n",
        "\n",
        "#lables of testing data\n",
        "# %cd /content\n",
        "test_labels = []\n",
        "\n",
        "# \"convert tsv file into dictioary\" TEST\n",
        "tsv_file = open(r\"C:\\Users\\Administrator\\Desktop\\Untitled Folder\\data\\tsv\\stimulus_NaturalImageTest.tsv\")\n",
        "read_tsv = csv. reader(tsv_file, delimiter=\"\\t\")\n",
        "df = pd.DataFrame(read_tsv)\n",
        "df = df.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "for i in range(0,50):\n",
        "  m = df['label'][df['ID'] == str(stimulusID_test[i][0])]\n",
        "  e = int(m)-1\n",
        "  test_labels.append(e+150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbGZHnTJ75X2"
      },
      "outputs": [],
      "source": [
        "raw_labels = np.concatenate([train_labels, test_labels])\n",
        "raw_labels = raw_labels.astype(float)\n",
        "labels = raw_labels\n",
        "newlabels = labels\n",
        "\n",
        "total_blocks = fmri.shape[0]\n",
        "fmri_size = fmri.shape[1]\n",
        "print('total blocks:'+str(total_blocks))\n",
        "print('input fmri size:'+str(fmri_size))\n",
        "\n",
        "test_num = 50 # ghablan 10 bood man avaz kardam\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, fmri_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(fmri_size, 1024),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(1024,512),\n",
        "            # # nn.Tanh(),\n",
        "            # nn.Linear(1024,512),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(1024, 64),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.classify = nn.Sequential(\n",
        "            nn.Linear(64, 150), #ghablan 2 bood\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, fmri):\n",
        "        fmri_flat = fmri.view(fmri.shape[0], -1)\n",
        "        semantics = self.model(fmri_flat)\n",
        "        x = self.classify(semantics)\n",
        "        return x, semantics\n",
        "\n",
        "# Use binary cross-entropy loss\n",
        "adversarial_loss = torch.nn.CrossEntropyLoss()\n",
        "encoder = Decoder(fmri_size=fmri_size)\n",
        "\n",
        "if cuda:\n",
        "    encoder.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_E = torch.optim.Adam(encoder.parameters(), lr=lr, betas=(b1, b2))\n",
        "scheduler_E = torch.optim.lr_scheduler.StepLR(optimizer_E, step_size=10, gamma=0.8, last_epoch=-1)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "\n",
        "fmri = np.concatenate([train_fmri, test_fmri])\n",
        "\n",
        "train_labels = labels[0:6000]\n",
        "test_labels = labels[6000:6050]\n",
        "labels = np.concatenate([train_labels, test_labels])\n",
        "labels = labels.astype(float)\n",
        "\n",
        "fmri = torch.from_numpy(fmri)\n",
        "fmri = fmri.type(Tensor)\n",
        "\n",
        "train_fmri = torch.from_numpy(train_fmri)\n",
        "train_labels = torch.from_numpy(train_labels)\n",
        "train_labels = train_labels.squeeze()\n",
        "train_fmri = train_fmri.type(Tensor)\n",
        "train_labels = train_labels.type(Tensor)\n",
        "\n",
        "test_fmri = torch.from_numpy(test_fmri)\n",
        "test_labels = torch.from_numpy(test_labels)\n",
        "test_labels = test_labels.squeeze()\n",
        "test_fmri = test_fmri.type(Tensor)\n",
        "test_labels = test_labels.type(Tensor)\n",
        "\n",
        "acc_vec = []\n",
        "train_vec = []\n",
        "loss_vec = []\n",
        "final_t_loss = []\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(0, 120):\n",
        "            fmri_data = train_fmri[i*batch_size:(i+1) * batch_size]\n",
        "            labels_data = train_labels[i*batch_size:(i+1) * batch_size]\n",
        "            labels_data = labels_data.long()\n",
        "            optimizer_E.zero_grad()\n",
        "            predict, _ = encoder(fmri_data)\n",
        "            print(\"shape of predicted\")\n",
        "            print(predict.shape)\n",
        "            print(\"shape of labels\")\n",
        "            print(labels_data.shape)\n",
        "            e_loss = adversarial_loss(predict, labels_data)\n",
        "            e_loss.backward()\n",
        "            optimizer_E.step()\n",
        "            loss_vec.append(e_loss.item())\n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d] [loss: %f] \"\n",
        "                % (epoch, n_epochs, i, e_loss.item())\n",
        "            )\n",
        "\n",
        "    # if epoch % 1 == 0:\n",
        "    #         test_fmri_data = test_fmri\n",
        "    #         # test_label_data = test_labels.cpu().detach().numpy()\n",
        "    #         test_labels = test_labels.long()\n",
        "    #         lbs, _ = encoder(test_fmri_data)\n",
        "    #         test_loss = adversarial_loss(lbs,test_labels)\n",
        "    #         final_t_loss.append(test_loss.item())\n",
        "            # cpu_labels = lbs.cpu().detach().numpy()\n",
        "            # pred = [np.argmax(lb) for lb in cpu_labels]\n",
        "            # num_correct = (pred == test_label_data).sum()\n",
        "            # acc = num_correct / 50\n",
        "            # acc_vec.append(acc)\n",
        "\n",
        "\n",
        "    scheduler_E.step()\n",
        "    lrd = optimizer_E.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Loss of classification on training Data')\n",
        "plt.plot(loss_vec)\n",
        "plt.xlabel('Epoch num * number of batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Loss of classification on test Data - 200 class')\n",
        "plt.plot(final_t_loss)\n",
        "plt.xlabel('Epoch num * number of batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "pred, sm = encoder(fmri)\n",
        "torch.save(sm,'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Untitled Folder\\\\data\\\\tsv\\\\semantics')\n",
        "print(len(sm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq778-1djEqc"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"loss_semantic_train.csv\", loss_vec, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdpiUMKzkV3A"
      },
      "source": [
        "# **Augmentation Semantic Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWiXP0dXka41"
      },
      "outputs": [],
      "source": [
        "aug_label = []\n",
        "for i in range(149):\n",
        "  if i <=54:\n",
        "    for j in range(8):\n",
        "      aug_label.append(i)\n",
        "  else:\n",
        "    for j in range(8):\n",
        "      aug_label.append(i+1)\n",
        "\n",
        "for j in range(8):\n",
        "  aug_label.append(55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzbM2vbXiBMW"
      },
      "outputs": [],
      "source": [
        "#select Training images that correspond to stimulusID\n",
        "import shutil\n",
        "%cd /content/\n",
        "original_path = '/content/drive/MyDrive/augmented_images/final_aug/'\n",
        "target_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "\n",
        "new_name = 6000\n",
        "for picture_name in range(7000,8200):\n",
        "\n",
        "  new_original = os.path.join(original_path, str(picture_name) + \".jpg\")\n",
        "  if os.path.isfile(new_original):\n",
        "    new_target = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    shutil.copyfile(new_original, new_target)\n",
        "    #new_dir = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    #os.rename(file_path, new_dir)\n",
        "  new_original = \"\"\n",
        "  new_target = \"\"\n",
        "  new_name = int(new_name) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsjOY1gEDC-"
      },
      "outputs": [],
      "source": [
        "#aug images\n",
        "\n",
        "\n",
        "newSize = 128\n",
        "patch_num = 128\n",
        "aug_imgs = np.zeros((1200,newSize,newSize))\n",
        "patch_aug_imgs = np.zeros((1200,patch_num,patch_num))\n",
        "img_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "filelist = os.listdir(img_path)\n",
        "num = 0\n",
        "\n",
        "\n",
        "for d in range(6000,7200):\n",
        "    new_aug = cv2.imread(img_path +'%d.JPEG' %d)\n",
        "    new_imgs = color.rgb2gray(new_aug)\n",
        "    new_imgs = cv2.resize(new_imgs, dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "    # image = patch_train_imgs[num,:,:]\n",
        "    patch_aug_imgs[num,:,:] = cv2.normalize(new_imgs, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    one = patch_aug_imgs[num,:,:]\n",
        "    for i in range (128):\n",
        "      for j in range(128):\n",
        "          if one[i][j]<=0.5:\n",
        "            one[i][j] = 1\n",
        "\n",
        "          else:\n",
        "            one[i][j] = 0\n",
        "\n",
        "    patch_aug_imgs[num,:,:] = one\n",
        "    num = num +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsjwsJ3YySHz"
      },
      "outputs": [],
      "source": [
        "train_labels_new = train_labels.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-rtKI2vyzyP"
      },
      "outputs": [],
      "source": [
        "semantic_vecs = torch.load('/content/drive/MyDrive/thesis/data/sm_features/demo1/semantics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-e78VshzM2q"
      },
      "outputs": [],
      "source": [
        "aug_semantic = np.zeros([1200,64])\n",
        "import torch\n",
        "num = 0\n",
        "b = semantic_vecs.to(torch.device(\"cpu\"))\n",
        "c = b.detach().numpy()\n",
        "\n",
        "for i in aug_label:\n",
        "\n",
        "  address = np.where(train_labels_new == i)[0]\n",
        "  d = c[address].mean(axis = 0)\n",
        "  aug_semantic[num,:] = d\n",
        "  num = num +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_7qcWIPthZD"
      },
      "outputs": [],
      "source": [
        "aug_train = np.concatenate((c[0:6000],aug_semantic), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_rDwH4sHjNI"
      },
      "outputs": [],
      "source": [
        "print(len(aug_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CarAF5lUPUEk"
      },
      "source": [
        "# **5. Change Name of Training Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuA0uytMdaJR"
      },
      "outputs": [],
      "source": [
        "#select Training images that correspond to stimulusID\n",
        "import shutil\n",
        "%cd /content/\n",
        "# \"convert tsv file into dictioary\"\n",
        "tsv_file = open(\"/content/drive/MyDrive/Stimulus_excel/stimulus_NaturalImageTraining.tsv\")\n",
        "read_tsv = csv. reader(tsv_file, delimiter=\"\\t\")\n",
        "df = pd.DataFrame(read_tsv)\n",
        "df = df.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "df['label'] = df['label'].astype(float, errors = 'raise')\n",
        "train_labels = df[\"label\"]\n",
        "#train_labels = np.array(train_labels)\n",
        "print(train_labels.dtype)\n",
        "df.drop(['label','num'] , inplace=True, axis=1)\n",
        "\n",
        "dict_train = dict(zip(df.ID, df.Name))\n",
        "print(dict_train)\n",
        "nameStimulus = []\n",
        "# \"find ID's that correspond to Image name\"\n",
        "for ID in stimulusID:\n",
        "  #res = {sub['name'] : sub['age'] for ID in test_list}\n",
        "  res = {float(key) : dict_train[key] for key in dict_train}\n",
        "  convK = float(ID)\n",
        "  res = res[convK]\n",
        "  nameStimulus.append(res)\n",
        "\n",
        "\n",
        "print(nameStimulus)\n",
        "#directory_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "original_path = '/content/drive/MyDrive/thesis/data/images/demo1/result/training/'\n",
        "# original_path = '/content/drive/MyDrive/thesis/data/images/demo1/fff/'\n",
        "target_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "\n",
        "nameStimulus = nameStimulus[0:6000]\n",
        "new_name = 0\n",
        "for picture_name in nameStimulus:\n",
        "\n",
        "  new_original = os.path.join(original_path, picture_name + \".png\")\n",
        "  if os.path.isfile(new_original):\n",
        "    new_target = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    shutil.copyfile(new_original, new_target)\n",
        "    #new_dir = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    #os.rename(file_path, new_dir)\n",
        "  new_original = \"\"\n",
        "  new_target = \"\"\n",
        "  new_name = int(new_name) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ejku4RI6uH8"
      },
      "outputs": [],
      "source": [
        "#select Test images that correspond to stimulusID\n",
        "import shutil\n",
        "%cd /content/\n",
        "# \"convert tsv file into dictioary\"\n",
        "test_file = open(\"/content/drive/MyDrive/Stimulus_excel/stimulus_NaturalImageTest.tsv\")\n",
        "test_tsv = csv. reader(test_file, delimiter=\"\\t\")\n",
        "df_test = pd.DataFrame(test_tsv)\n",
        "df_test = df_test.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "df_test['label'] = df_test['label'].astype(float, errors = 'raise')\n",
        "test_labels = df_test['label']\n",
        "df_test.drop(['label','num'] , inplace=True, axis=1)\n",
        "\n",
        "\n",
        "dict_test = dict(zip(df_test.ID, df_test.Name))\n",
        "#print(dict_test)\n",
        "\n",
        "nameStimulus = []\n",
        "# \"find ID's that correspond to Image name\"\n",
        "for ID in stimulusID_test:\n",
        "\n",
        "  res = {float(key) : dict_test[key] for key in dict_test}\n",
        "  convK = float(ID)\n",
        "  res = res[convK]\n",
        "  nameStimulus.append(res)\n",
        "\n",
        "original_path = '/content/drive/MyDrive/thesis/data/images/demo1/result/test/'\n",
        "# original_path = '/content/drive/MyDrive/thesis/data/images/demo1/original_imgs/'\n",
        "# original_path = '/content/drive/MyDrive/thesis/data/images/demo1/fff/'\n",
        "target_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "\n",
        "new_name = 6000\n",
        "nameStimulus = nameStimulus[0:50]\n",
        "for picture_name in nameStimulus:\n",
        "\n",
        "  new_original = os.path.join(original_path, picture_name + \".png\")\n",
        "  if os.path.isfile(new_original):\n",
        "    new_target = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    shutil.copyfile(new_original, new_target)\n",
        "    #new_dir = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    #os.rename(file_path, new_dir)\n",
        "    new_original = \"\"\n",
        "    new_target = \"\"\n",
        "  else:\n",
        "    new_original = \"\"\n",
        "    new_target = \"\"\n",
        "  new_name = int(new_name) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mLLjxS2anZk"
      },
      "source": [
        "# **6. Load Training and Test Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0e5GmtCQc2f"
      },
      "outputs": [],
      "source": [
        "#training images\n",
        "import skimage.measure\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "\n",
        "newSize = 128\n",
        "patch_num = 128\n",
        "train_imgs = np.zeros((6000,newSize,newSize))\n",
        "patch_train_imgs = np.zeros((6000,patch_num,patch_num))\n",
        "img_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "filelist = os.listdir(img_path)\n",
        "num = 0\n",
        "\n",
        "\n",
        "for d in range(0,6000):\n",
        "    new_train = cv2.imread(img_path +'%d.JPEG' %d)\n",
        "    new_imgs = color.rgb2gray(new_train)\n",
        "    new_imgs = cv2.resize(new_imgs, dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "    # image = patch_train_imgs[num,:,:]\n",
        "    patch_train_imgs[num,:,:] = cv2.normalize(new_imgs, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    one = patch_train_imgs[num,:,:]\n",
        "    for i in range (128):\n",
        "      for j in range(128):\n",
        "          if one[i][j]<=0.5:\n",
        "            one[i][j] = 1\n",
        "\n",
        "          else:\n",
        "            one[i][j] = 0\n",
        "\n",
        "    patch_train_imgs[num,:,:] = one\n",
        "    num = num +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2xUMcaO3tHg"
      },
      "outputs": [],
      "source": [
        "#test images\n",
        "newSize = 128\n",
        "patch_num = 128\n",
        "test_imgs = np.zeros((50,newSize,newSize))\n",
        "img_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "filelist = os.listdir(img_path)\n",
        "patch_test_imgs = np.zeros((50,patch_num,patch_num))\n",
        "num = 0\n",
        "\n",
        "for d in range(6000,6050):\n",
        "\n",
        "    new_test = cv2.imread(img_path +'%d.JPEG' %d)\n",
        "    new_imgs = color.rgb2gray(new_test)\n",
        "    new_imgs = cv2.resize(new_imgs, dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "    patch_test_imgs[num,:,:] = cv2.normalize(new_imgs, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    one = patch_test_imgs[num,:,:]\n",
        "    for i in range (128):\n",
        "      for j in range(128):\n",
        "          if one[i][j]<=0.5:\n",
        "            one[i][j] = 1\n",
        "\n",
        "          else:\n",
        "            one[i][j] = 0\n",
        "\n",
        "    patch_test_imgs[num,:,:] = one\n",
        "    num = num + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qffmQcXsOPX"
      },
      "outputs": [],
      "source": [
        "for i in range(50):\n",
        "  plt.figure()\n",
        "  plt.imshow(patch_test_imgs[i], cmap = 'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA5XrLRb23Rw"
      },
      "outputs": [],
      "source": [
        "one_imgs = cv2.resize(patch_train_imgs[1,:,:], dsize = (32, newSize), interpolation=cv2.INTER_CUBIC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Gsc5BPIn_4"
      },
      "outputs": [],
      "source": [
        "#convert Train Image to vec\n",
        "obj_vector_train = np.zeros((6000,16384))\n",
        "\n",
        "for i in range(6000):\n",
        "  images = patch_train_imgs[i]\n",
        "\n",
        "  flat_imgs = images.flatten()\n",
        "  obj_vector_train[i] = flat_imgs\n",
        "\n",
        "obj_vector_train = obj_vector_train.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwZkgIiqwudA"
      },
      "outputs": [],
      "source": [
        "#convert Test Image to vec\n",
        "obj_vector_test = np.zeros((50,16384))\n",
        "\n",
        "for i in range(50):\n",
        "  images = patch_test_imgs[i]\n",
        "\n",
        "  flat_imgs = images.flatten()\n",
        "  # for j in flat_imgs:\n",
        "  #   j = float(j)\n",
        "  obj_vector_test[i] = flat_imgs\n",
        "\n",
        "obj_vector_test = obj_vector_test.astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH5Vxf0_Pwlm"
      },
      "source": [
        "# **7. Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwYqBLjQNQqM"
      },
      "outputs": [],
      "source": [
        "#plot function\n",
        "\n",
        "def plot_train(loss_train,validation_loss,name,x_label,y_label):\n",
        "  # plt.figure()\n",
        "  # plt.title(name)\n",
        "  # plt.plot(loss_train)\n",
        "  # plt.plot(validation_loss)\n",
        "  # plt.xlabel(x_label)\n",
        "  # plt.ylabel(y_label)\n",
        "  # plt.show()\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(2)\n",
        "  fig.suptitle('Vertically stacked subplots')\n",
        "  ax1.plot(loss_train)\n",
        "  ax2.plot(validation_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAkuDvbu0qEE"
      },
      "outputs": [],
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "##############################\n",
        "#           U-NET\n",
        "##############################\n",
        "\n",
        "\n",
        "class UNetDown(nn.Module):\n",
        "    def __init__(self, in_size, out_size= 3, normalize=True, dropout=0.0):\n",
        "        super(UNetDown, self).__init__()\n",
        "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
        "        if normalize:\n",
        "            layers.append(nn.InstanceNorm2d(out_size))\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    def __init__(self, in_size, out_size = 3, dropout=0.0):\n",
        "        super(UNetUp, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(out_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.model(x)\n",
        "        x = torch.cat((x, skip_input), 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "##############################\n",
        "#        Discriminator\n",
        "##############################\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalization:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 3, 4, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        img_input = torch.cat((img_A, img_B), 1)\n",
        "        return self.model(img_input)\n",
        "\n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super(GeneratorUNet, self).__init__()\n",
        "\n",
        "        self.down1 = UNetDown(in_channels, 64, normalize=True)\n",
        "        self.down2 = UNetDown(64, 128)\n",
        "        self.down3 = UNetDown(128, 256)\n",
        "        self.down4 = UNetDown(256, 512)\n",
        "        self.down5 = UNetDown(512, 512)\n",
        "        self.down6 = UNetDown(512, 512)\n",
        "        self.down7 = UNetDown(512, 512)\n",
        "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
        "\n",
        "        self.up1 = UNetUp(576, 512, dropout=0.5)\n",
        "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up5 = UNetUp(1024, 256)\n",
        "        self.up6 = UNetUp(512, 128)\n",
        "        self.up7 = UNetUp(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, semantic_vec):\n",
        "        # U-Net generator with skip connections from encoder to decoder\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "        d7 = self.down7(d6)\n",
        "        d8 = self.down8(d7)\n",
        "\n",
        "        semantic_vec = semantic_vec.unsqueeze(2)\n",
        "        semantic_vec = semantic_vec.unsqueeze(3)\n",
        "        d8 = torch.cat((d8, semantic_vec), 1)\n",
        "\n",
        "        u1 = self.up1(d8, d7)\n",
        "        u2 = self.up2(u1, d6)\n",
        "        u3 = self.up3(u2, d5)\n",
        "        u4 = self.up4(u3, d4)\n",
        "        u5 = self.up5(u4, d3)\n",
        "        u6 = self.up6(u5, d2)\n",
        "        u7 = self.up7(u6, d1)\n",
        "\n",
        "        return self.final(u7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdEDS6X401_I"
      },
      "outputs": [],
      "source": [
        "#dataset.py\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, mode=\"train\"):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "\n",
        "        self.files = sorted(glob.glob(os.path.join(root, mode) + \"/*.*\"))\n",
        "        if mode == \"train\":\n",
        "            self.files.extend(sorted(glob.glob(os.path.join(root, \"test\") + \"/*.*\")))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.open(self.files[index % len(self.files)])\n",
        "        w, h = img.size\n",
        "        img_A = img.crop((0, 0, w / 2, h))\n",
        "        img_B = img.crop((w / 2, 0, w, h))\n",
        "        img_A = self.transform(img_A)\n",
        "        img_B = self.transform(img_B)\n",
        "\n",
        "        return {\"A\": img_A, \"B\": img_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQPMTTXtIfmB"
      },
      "outputs": [],
      "source": [
        "#SSIM Function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import data, img_as_float\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import mean_squared_error\n",
        "\n",
        "def ssim_function(real_img,fake_img,rand_img):#real image is a real test image, fake is reconstruction real_imgs and random image is random reconstructed image\n",
        "\n",
        "  #sum_RI = 0\n",
        "  #sum_RRI = 0\n",
        "  img1 = img_as_float(real_img)\n",
        "  img = color.rgb2gray(img1)\n",
        "  rows, cols = img.shape\n",
        "\n",
        "  #noise = np.ones_like(img) * 0.2 * (img.max() - img.min())\n",
        "  #rng = np.random.default_rng()\n",
        "  #noise[rng.random(size=noise.shape) > 0.5] *= -1\n",
        "\n",
        "  img_noise = fake_img\n",
        "  img_const = rand_img\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 4),\n",
        "                          sharex=True, sharey=True)\n",
        "  ax = axes.ravel()\n",
        "\n",
        "  mse_none = mean_squared_error(img, img)\n",
        "  ssim_none = ssim(img, img, data_range=img.max() - img.min())\n",
        "\n",
        "  mse_noise = mean_squared_error(img, img_noise)\n",
        "  ssim_noise = ssim(img, img_noise,\n",
        "                    data_range=img_noise.max() - img_noise.min())\n",
        "\n",
        "  mse_const = mean_squared_error(img, img_const)\n",
        "  ssim_const = ssim(img, img_const,\n",
        "                    data_range=img_const.max() - img_const.min())\n",
        "\n",
        "\n",
        "\n",
        "  # ax[0].imshow(img, cmap=plt.cm.gray)\n",
        "  ax[0].imshow(img)\n",
        "  ax[0].set_xlabel(f'MSE: {mse_none:.2f}, SSIM: {ssim_none:.2f}')\n",
        "  ax[0].set_title('real image')\n",
        "\n",
        "  ax[1].imshow(img_noise)\n",
        "  ax[1].set_xlabel(f'MSE: {mse_noise:.2f}, SSIM: {ssim_noise:.2f}')\n",
        "  ax[1].set_title('reconstructed image')\n",
        "\n",
        "  ax[2].imshow(img_const)\n",
        "  ax[2].set_xlabel(f'MSE: {mse_const:.2f}, SSIM: {ssim_const:.2f}')\n",
        "  ax[2].set_title('reconstructed random image')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  return ssim_noise, ssim_const"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwWmOyCqgQ45"
      },
      "outputs": [],
      "source": [
        "class DecoderDataset(Dataset):\n",
        "  def __init__(self, fmri_train, train_imgs):\n",
        "    self.datax = torch.tensor(fmri_train, dtype = torch.float32)\n",
        "    self.datay = torch.tensor(train_imgs, dtype = torch.float32)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    itemx = self.datax[item]\n",
        "    itemy = self.datay[item].flatten()\n",
        "    return itemx, itemy\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.datax.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c28brleX1iVJ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, patch_imgs, sp_imgs_v1, sp_imgs_v2, sp_imgs_v3, pixel):\n",
        "    self.pix = pixel\n",
        "    self.patch = patch_imgs\n",
        "    self.sp_v1 = sp_imgs_v1\n",
        "    self.sp_v2 = sp_imgs_v2\n",
        "    self.sp_v3 = sp_imgs_v3\n",
        "\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "\n",
        "    item_v1 = self.sp_v1[item, self.pix[0], self.pix[1]]\n",
        "    item_v2 = self.sp_v2[item, self.pix[0], self.pix[1]]\n",
        "    item_v3 = self.sp_v3[item, self.pix[0], self.pix[1]]\n",
        "    item_patch = self.patch[item, self.pix[0], self.pix[1]]\n",
        "\n",
        "    datax = torch.tensor(np.array((item_v1, item_v2, item_v3)), dtype= torch.float32)\n",
        "    datay = torch.tensor(item_patch , dtype = torch.float32)\n",
        "\n",
        "    return datax, datay\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.patch.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAzziEGmyyQC"
      },
      "outputs": [],
      "source": [
        "#linear layer\n",
        "class Aggregation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Aggregation, self).__init__()\n",
        "        self.fc = nn.Linear(in_features=3, out_features=1, bias = False )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OdBFIna0Zcl"
      },
      "outputs": [],
      "source": [
        "def unpoolingAvg(mat, f, ori_shape):\n",
        "    '''Undo an average-pooling of a 2d or 3d array to a larger size\n",
        "\n",
        "    Args:\n",
        "        mat (ndarray): 2d or 3d array to unpool on the first 2 dimensions.\n",
        "        f (int): pooling kernel size.\n",
        "        ori_shape (tuple): original shape to unpool to.\n",
        "    Returns:\n",
        "        result (ndarray): <mat> unpoolled to shape <ori_shape>.\n",
        "    '''\n",
        "    m, n = ori_shape[:2]\n",
        "    ny = m//f\n",
        "    nx = n//f\n",
        "\n",
        "    tmp = np.reshape(mat, (ny, 1, nx, 1)+mat.shape[2:])\n",
        "    tmp = np.repeat(tmp, f, axis=1)\n",
        "    tmp = np.repeat(tmp, f, axis=3)\n",
        "    tmp = np.reshape(tmp, (ny*f, nx*f)+mat.shape[2:])\n",
        "    result=np.zeros(ori_shape)\n",
        "\n",
        "    result[:tmp.shape[0], :tmp.shape[1], ...]= tmp\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIxeTnWjnffP"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "  \"\"\"Computes and stores the average and current value\"\"\"\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFxU2PEmv4pk"
      },
      "outputs": [],
      "source": [
        "#cuda\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZWaGkbKc4e6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Training contour decoders\n",
        "Reconstruct shapes of stimulus images from the fMRI inputs\n",
        "'''\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import random\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "def rasterize_img(img, out_size):\n",
        "    raw_sz = img.shape[1]\n",
        "    per_check = raw_sz/out_size\n",
        "    new_arr = np.zeros((1, out_size, out_size))\n",
        "    for l in range(out_size):\n",
        "        for p in range(out_size):\n",
        "            sx = int(l*per_check)\n",
        "            ex = int((l+1)*per_check)\n",
        "            sy = int(p*per_check)\n",
        "            ey = int((p+1)*per_check)\n",
        "            check = img[0, sx:ex, sy:ey]\n",
        "            sum = np.sum(np.reshape(check, (check.size,)))\n",
        "            avg = sum*1.0 / (per_check*per_check)\n",
        "            new_arr[0, l, p] = avg\n",
        "    return new_arr\n",
        "\n",
        "\n",
        "def de_rasterize_img(img, out_size):\n",
        "    raw_sz = img.shape[1]\n",
        "    times = out_size/raw_sz\n",
        "    new_arr = np.zeros((1, out_size, out_size))\n",
        "    for l in range(raw_sz):\n",
        "        for p in range(raw_sz):\n",
        "            sx = int(l*times)\n",
        "            ex = int((l+1)*times)\n",
        "            sy = int(p*times)\n",
        "            ey = int((p+1)*times)\n",
        "            new_arr[0, sx:ex, sy:ey] = img[0, l, p]\n",
        "    return new_arr\n",
        "\n",
        "\n",
        "class Decoder_sh(nn.Module):\n",
        "    def __init__(self, fmri_size, latent_dim):\n",
        "        super(Decoder_sh, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # nn.Linear(fmri_size, 1400),#1765\n",
        "            # nn.Sigmoid(),\n",
        "            # nn.Linear(1400,1200),\n",
        "            # nn.Sigmoid(),\n",
        "            # nn.Linear(1200,latent_dim),\n",
        "            # nn.Tanh()\n",
        "            #*****\n",
        "            nn.Linear(fmri_size,latent_dim),\n",
        "            nn.Tanh()\n",
        "            # nn.Linear(fmri_size, fmri_size),#1765\n",
        "            # # nn.Sigmoid(), #Sigmoid\n",
        "            # nn.Linear(fmri_size, 1300),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(1300,latent_dim),\n",
        "            # nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        x = self.model(img_flat)\n",
        "        return x\n",
        "\n",
        "\n",
        "def save_demo1_images(sp_imgs, raw_imgs):\n",
        "    for i in range(6000, 6050):\n",
        "        plt.figure()\n",
        "        im = sp_imgs[i]\n",
        "        br = (np.array(im) * 255).astype(np.uint8)\n",
        "        im = Image.fromarray(br[i])\n",
        "        im = im.convert('RGB')\n",
        "\n",
        "        zr = (np.array(raw_imgs) * 255).astype(np.uint8)\n",
        "        raw_img = Image.fromarray(zr[i])\n",
        "        raw_img = raw_img.convert('RGB')\n",
        "        target = Image.new('RGB', (256 * 2, 256))\n",
        "        target.paste(raw_img, (0, 0, 256, 256))\n",
        "        target.paste(im, (256, 0, 512, 256))\n",
        "        target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "        target = target.convert('L')\n",
        "        target = np.asarray(target)\n",
        "        target = target[:, ::-1]\n",
        "\n",
        "        ax = plt.subplot(1, 1, 1)\n",
        "        plt.imshow(np.fliplr(target), cmap='hot')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        plt.savefig(\"/content/drive/MyDrive/thesis/results/digits/shape_decoding%d.png\" % i)\n",
        "\n",
        "\n",
        "def decoding_shapes(train_fmri, train_imgs, test_fmri, test_imgs, output_size, n_epochs, batch_size,lr, b1=0.5, b2=0.9):\n",
        "\n",
        "\n",
        "    latent_dim = output_size*output_size\n",
        "    # rand_id = np.random.randint(low=0, high=train_fmri.shape[0], size=train_fmri.shape[0]) #shuffle with replacement\n",
        "    rand_id = random.sample(range(train_fmri.shape[0]), train_fmri.shape[0]) #shuffle without replacement\n",
        "    train_fmri = train_fmri[rand_id]\n",
        "    train_imgs = output_encoder\n",
        "    test_imgs = output_encoder_test\n",
        "    fmri = np.concatenate([train_fmri, test_fmri])\n",
        "    train_imgs = train_imgs[rand_id]\n",
        "    imgs = np.concatenate([train_imgs, test_imgs])\n",
        "\n",
        "    # raw_imgs =  np.concatenate([patch_train_imgs, patch_test_imgs])\n",
        "    total_blocks = fmri.shape[0] #1250\n",
        "    fmri_size = fmri.shape[1]\n",
        "\n",
        "    train_num = total_blocks - 50 #10 bood\n",
        "    batch_num = train_num / batch_size #9\n",
        "\n",
        "    print('Train blocks:'+str(train_num))\n",
        "    print('batch num:' + str(batch_num))\n",
        "    cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "\n",
        "    # Use binary cross-entropy loss\n",
        "    adversarial_loss = torch.nn.BCELoss()\n",
        "    pixelwise_loss = torch.nn.L1Loss()\n",
        "    #pixelwise_loss = torch.nn.MSELoss()\n",
        "    # pixelwise_loss = torch.nn.BCELoss()\n",
        "    # Initialize generator and discriminator\n",
        "    decoder = Decoder_sh(fmri_size=fmri_size, latent_dim=latent_dim)\n",
        "\n",
        "    if cuda:\n",
        "        decoder.cuda()\n",
        "        adversarial_loss.cuda()\n",
        "        pixelwise_loss.cuda()\n",
        "\n",
        "\n",
        "    optimizer_E = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "    scheduler_E = torch.optim.lr_scheduler.StepLR(optimizer_E, step_size=5, gamma=0.7, last_epoch=-1)#step size 5 bood\n",
        "\n",
        "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "    # ----------\n",
        "    #  Training\n",
        "    # ----------\n",
        "    loss_train = []\n",
        "    validation_loss = []\n",
        "    fmri = torch.from_numpy(fmri)\n",
        "    fmri = fmri.type(Tensor)\n",
        "    imgs = torch.from_numpy(imgs)\n",
        "    imgs = imgs.type(Tensor)\n",
        "    for epoch in range(n_epochs + 1):\n",
        "        decoder.train()\n",
        "        for i in range(0, int(batch_num)):\n",
        "            fmri_data = fmri[i * batch_size:(i + 1) * batch_size]\n",
        "            print(list(fmri_data.size()))\n",
        "            real_imgs = imgs[i * batch_size:(i + 1) * batch_size]\n",
        "            optimizer_E.zero_grad()\n",
        "            latent_vector = decoder(fmri_data)\n",
        "            print(\"latent vec size\")\n",
        "            print(list(latent_vector.size()))\n",
        "            obj_vector = real_imgs.reshape(real_imgs.shape[0], -1)\n",
        "            e_loss = pixelwise_loss(obj_vector, latent_vector)\n",
        "            e_loss.backward()\n",
        "            optimizer_E.step()\n",
        "            #print(type(e_loss))\n",
        "            loss_train.append(e_loss.item())\n",
        "\n",
        "\n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d] [E loss: %f]\"\n",
        "                % (epoch, n_epochs, i, e_loss.item()) #train_loss\n",
        "            )\n",
        "            decoder.eval()\n",
        "            with torch.no_grad():\n",
        "              y_v_pred = decoder(fmri[train_num:train_num + batch_size])\n",
        "              obj_test_vector = test_imgs.reshape(test_imgs.shape[0], -1)\n",
        "              #print(type(obj_test_vector))\n",
        "              obj_test_vector = torch.tensor(obj_test_vector, dtype = torch.float32)\n",
        "              obj_test_vector = obj_test_vector.to(\"cuda\")\n",
        "              v_loss = pixelwise_loss(obj_test_vector, y_v_pred)\n",
        "              validation_loss.append(v_loss.item())\n",
        "            print(v_loss.item()) #test loss\n",
        "\n",
        "        if epoch % 50 == 0: #10 bood\n",
        "          test_fmri_data = fmri[train_num:train_num + batch_size]\n",
        "          print(\"*\" * 200)\n",
        "          print(test_fmri_data.shape)\n",
        "          latent_v = decoder(test_fmri_data)\n",
        "          latent_v = latent_v.view(batch_size, 1, output_size, output_size)\n",
        "\n",
        "          tempv = latent_v.data\n",
        "    decoder.eval()\n",
        "    imgs = decoder(fmri)\n",
        "    imgs = imgs.view(fmri.shape[0], output_size, output_size)\n",
        "    imgs = imgs.data.cpu() * 255.0\n",
        "    imgs = np.asarray(imgs)\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('Loss of Base Decoder(V3) on Training Data')\n",
        "    plt.plot(loss_train)\n",
        "    plt.xlabel('number of epoch * number of batch')\n",
        "    plt.ylabel('L1 loss')\n",
        "\n",
        "    # xpoints = [i for i in range(1200)]\n",
        "\n",
        "    # plt.plot(ypoints)\n",
        "    plt.figure()\n",
        "    # plt.plot(final_l)\n",
        "    plt.title('Loss of Base Decoder(V3) on Test Data')\n",
        "    plt.plot(validation_loss)\n",
        "    plt.xlabel('number of epoch * number of batch')\n",
        "    plt.ylabel('L1 loss')\n",
        "\n",
        "    # plot_train(loss_train,validation_loss,'pixelwise loss','number of epoch * number of batch','loss')\n",
        "    #save_demo1_images(imgs, raw_imgs)\n",
        "    return decoder, imgs, rand_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTWPPgqd1NJy"
      },
      "outputs": [],
      "source": [
        "# rand_id = random.sample(range(train_fmri.shape[0]), train_fmri.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfmM7yPs1PSv"
      },
      "outputs": [],
      "source": [
        "# train_fmri.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-ftJF5Pp50S"
      },
      "source": [
        "# **Convolutional AE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpL7tweruNSz"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        ### Convolutional section\n",
        "        self.encoder_cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, stride=2, padding = 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding = 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Conv2d(64, 128, 3, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Conv2d(128, 256, 3, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(True)\n",
        "        )\n",
        "\n",
        "        ### Flatten layer\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        ### Linear section\n",
        "        self.encoder_lin = nn.Sequential(\n",
        "            nn.Linear(3 * 3 * 32, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, encoded_space_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_cnn(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.encoder_lin(x)\n",
        "        return x\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
        "        super().__init__()\n",
        "        self.decoder_lin = nn.Sequential(\n",
        "            nn.Linear(encoded_space_dim, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 3 * 3 * 32),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.unflatten = nn.Unflatten(dim=1,\n",
        "        unflattened_size=(32, 3, 3))\n",
        "\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, output_padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, output_padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, output_padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(32, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.LeakyReLU(True)\n",
        "            # nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.decoder_lin(x)\n",
        "        x = self.unflatten(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zECkMHHJvmQ"
      },
      "outputs": [],
      "source": [
        "encoded_space_dim = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJTzwRti34Zz"
      },
      "outputs": [],
      "source": [
        "encoder_cnn = nn.Sequential(\n",
        "  nn.Conv2d(1, 8, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(8),\n",
        "  nn.LeakyReLU(True),\n",
        "  nn.Conv2d(8, 16, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(16),\n",
        "  nn.LeakyReLU(True),\n",
        "  nn.Conv2d(16, 32, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(32),\n",
        "  nn.LeakyReLU(True),\n",
        "  nn.Conv2d(32, 64, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(64),\n",
        "  nn.LeakyReLU(True),\n",
        "  nn.Conv2d(64, 128, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(128),\n",
        "  nn.LeakyReLU(True),\n",
        "  nn.Conv2d(128, 256, 3, stride=2, padding = 1),\n",
        "  nn.BatchNorm2d(256),\n",
        "  nn.LeakyReLU(True)\n",
        "  # nn.Conv2d(512, 1024, 3, stride=2, padding = 1),\n",
        "  # nn.BatchNorm2d(1024),\n",
        "  # nn.LeakyReLU(True)\n",
        ")\n",
        "flatten = nn.Flatten(start_dim=1)\n",
        "\n",
        "# linear = nn.Sequential(\n",
        "#   nn.Linear(262144, 8192),\n",
        "#   nn.ReLU(True),\n",
        "#   nn.Linear(8192, encoded_space_dim)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulyNOyds3_vq"
      },
      "outputs": [],
      "source": [
        "one_imgs = torch.tensor(patch_train_imgs[0] , dtype = torch.float32)\n",
        "one_imgs = one_imgs.unsqueeze(dim = 0)\n",
        "one_imgs = one_imgs.unsqueeze(dim = 0)\n",
        "print(one_imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meMBHF9t4rmP"
      },
      "outputs": [],
      "source": [
        "out_put_encoder = encoder_cnn(one_imgs)\n",
        "print(out_put_encoder.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af63BPQi50kP"
      },
      "outputs": [],
      "source": [
        "output_flatten = flatten(out_put_encoder)\n",
        "print(output_flatten.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1J2oabs6cvY"
      },
      "outputs": [],
      "source": [
        "output_linear = linear(output_flatten)\n",
        "print(output_linear.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45bjfelf7pN0"
      },
      "outputs": [],
      "source": [
        "#Decoder\n",
        "# decoder_lin = nn.Sequential(\n",
        "#   nn.Linear(encoded_space_dim, 8192),\n",
        "#   nn.ReLU(True),\n",
        "#   nn.Linear(8192, 262144),\n",
        "#   nn.ReLU(True)\n",
        "# )\n",
        "\n",
        "unflatten = nn.Unflatten(dim=1,unflattened_size=(256, 2, 2))\n",
        "\n",
        "decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
        "            # nn.BatchNorm2d(1),\n",
        "            # nn.LeakyReLU(True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJL6RTuZ8JFS"
      },
      "outputs": [],
      "source": [
        "output_linearD = decoder_lin(output_flatten)\n",
        "print(output_linearD.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdyqm5ad9a9G"
      },
      "outputs": [],
      "source": [
        "output_unflatten = unflatten(output_flatten)\n",
        "print(output_unflatten.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaI0EPSn9tSS"
      },
      "outputs": [],
      "source": [
        "out_put_decoder = decoder_conv(output_unflatten)\n",
        "print(out_put_decoder.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMvsJYFM_cgr"
      },
      "source": [
        "# AE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkk9zIdy87kW"
      },
      "outputs": [],
      "source": [
        "#VAE(Variational Auto encoder)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(16384, 5000) #2^16\n",
        "        self.linear2 = nn.Linear(5000, latent_dims)\n",
        "        # self.linear3 = nn.Linear(2000, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        # x = F.relu(self.linear2(x))\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdHttjmP_kDl"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 5000)\n",
        "        self.linear2 = nn.Linear(5000, 16384)\n",
        "        # self.linear3 = nn.Linear(4000, 10000)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        # z = torch.sigmoid(self.linear3(z))\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdc3Qw4Z_pBr"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder(latent_dims)\n",
        "        self.decoder = Decoder(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQGwSFIT_tB4"
      },
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=150):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
        "    loss_train = []\n",
        "    for epoch in range(epochs):\n",
        "        for x in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            loss_train.append(loss.item())\n",
        "    return autoencoder,loss_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN43oaht_wLQ"
      },
      "outputs": [],
      "source": [
        "latent_dims = 1024\n",
        "autoencoder = Autoencoder(latent_dims).to(device) # GPU\n",
        "\n",
        "data = torch.utils.data.DataLoader(obj_vector_train,batch_size=50,shuffle= False)\n",
        "\n",
        "autoencoder, loss_train = train(autoencoder, data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnfXNXnkDKoU"
      },
      "outputs": [],
      "source": [
        "print((loss_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHsMpkY8DEe1"
      },
      "outputs": [],
      "source": [
        "# xpoints = [i for i in range(1200)]\n",
        "plt.figure()\n",
        "ypoints = loss_train\n",
        "plt.title('Loss of Auto Encoder on Training Data')\n",
        "plt.plot(ypoints)\n",
        "plt.xlabel('number of epoch * number of batch size')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(ypoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hquE68Phu_ZH"
      },
      "outputs": [],
      "source": [
        "ypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9iCw7kBjow0"
      },
      "outputs": [],
      "source": [
        "np.savetxt('AE_loss.csv', ypoints,delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy-928ovrFkp"
      },
      "outputs": [],
      "source": [
        "output_encoder = np.zeros((6000,1024))\n",
        "# loss_test = []\n",
        "for i , x in enumerate(data):\n",
        "  z = autoencoder.encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_encoder[i*50:(i+1)*50] = z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aw04KWfuKw_"
      },
      "outputs": [],
      "source": [
        "np.reshape(output_encoder,(6000,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_TFVD52w8oZ"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "data_test = torch.utils.data.DataLoader(obj_vector_test,batch_size=50,shuffle= False)\n",
        "output_encoder_test = np.zeros((50,1024))\n",
        "for i , x in enumerate(data_test):\n",
        "  z = autoencoder.encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_encoder_test[i*50:(i+1)*50] = z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVYOUcyIxVx9"
      },
      "source": [
        "# VAE(Variational Auto Encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tME4u17u6Blv"
      },
      "outputs": [],
      "source": [
        "class Decoder_vae(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Decoder_vae, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 5000)\n",
        "        self.linear2 = nn.Linear(5000, 16384)\n",
        "        # self.linear3 = nn.Linear(4000, 10000)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        # z = torch.sigmoid(self.linear3(z))\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GBoQ5OqxcLJ"
      },
      "outputs": [],
      "source": [
        "class VariationalEncoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(VariationalEncoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(16384, 5000)\n",
        "        self.linear2 = nn.Linear(5000, latent_dims)\n",
        "        self.linear3 = nn.Linear(5000, latent_dims)\n",
        "\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
        "        self.N.scale = self.N.scale.cuda()\n",
        "        self.kl = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        mu =  self.linear2(x)\n",
        "        sigma = torch.exp(self.linear3(x))\n",
        "        z = mu + sigma*self.N.sample(mu.shape)\n",
        "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFMJjqvWyHeB"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VariationalEncoder(latent_dims)\n",
        "        self.decoder = Decoder_vae(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JL-Wt2myIzC"
      },
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=800):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
        "\n",
        "    loss_train = []\n",
        "    for epoch in range(epochs):\n",
        "        for x in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum() + autoencoder.encoder.kl\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            loss_train.append(loss.item())\n",
        "    return autoencoder, loss_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSAs_MC9yPvx"
      },
      "outputs": [],
      "source": [
        "latent_dims = 1024\n",
        "data = torch.utils.data.DataLoader(obj_vector_train,batch_size=200,shuffle= False)\n",
        "autoencoder = VariationalAutoencoder(latent_dims).to(device) # GPU\n",
        "autoencoder, loss = train(autoencoder, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCt0T87_zJ9Y"
      },
      "outputs": [],
      "source": [
        "output_aencoder = np.zeros((6000,1024))\n",
        "# loss_test = []\n",
        "for i , x in enumerate(data):\n",
        "  z = autoencoder.encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_aencoder[i*200:(i+1)*200] = z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s8HKki8zbjP"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "data_test = torch.utils.data.DataLoader(obj_vector_test,batch_size=200,shuffle= False)\n",
        "output_aencoder_test = np.zeros((50,1024))\n",
        "for i , x in enumerate(data_test):\n",
        "  z = autoencoder.encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_aencoder_test[i*200:(i+1)*200] = z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoizSwiSCD8n"
      },
      "outputs": [],
      "source": [
        "np.reshape(output_aencoder,(6000,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7G9BdfkCT-4"
      },
      "outputs": [],
      "source": [
        "output_encoder = output_aencoder\n",
        "output_encoder_test = output_aencoder_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03_azcMP6YY5"
      },
      "outputs": [],
      "source": [
        "\n",
        "ypoints = loss\n",
        "# plt.plot(ypoints, color='green', linestyle='dashed', linewidth=2, markersize=12)\n",
        "plt.figure()\n",
        "plt.title('Loss of VAE on Training Data')\n",
        "plt.plot(ypoints)\n",
        "plt.xlabel('number of epoch * number of batch size')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(ypoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bKeSkJuvF19"
      },
      "outputs": [],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnO2kDQgYa8e"
      },
      "outputs": [],
      "source": [
        "np.savetxt('loss_VAE.csv',loss, delimiter = \",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9wY-rK_aWWF"
      },
      "source": [
        "# **Conv AE for MY Prob**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxSRJJwJGufa"
      },
      "outputs": [],
      "source": [
        "class CustomDataset1(Dataset):\n",
        "  def __init__(self, patch_imgs):\n",
        "    self.patch = torch.tensor(patch_imgs, dtype = torch.float32)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    datax = self.patch[item,:,:]\n",
        "    datax = torch.unsqueeze(datax, dim = 0)\n",
        "    return datax\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.patch.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWdv3OlMItBJ"
      },
      "outputs": [],
      "source": [
        "train_set = CustomDataset1(patch_train_imgs)\n",
        "test_set = CustomDataset1(patch_test_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OSVxZ2YJcC5"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=200, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=200, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gd9-YakJtey"
      },
      "outputs": [],
      "source": [
        "x = next(iter(test_loader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2TCjpe_a0_h"
      },
      "outputs": [],
      "source": [
        "encoded_space_dim = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjXU73b5abOu"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoded_space_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        ### Convolutional section\n",
        "        self.encoder_cnn = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.LeakyReLU(True),\n",
        "          nn.Conv2d(8, 16, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.LeakyReLU(True),\n",
        "          nn.Conv2d(16, 32, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.LeakyReLU(True),\n",
        "          nn.Conv2d(32, 64, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.LeakyReLU(True),\n",
        "          nn.Conv2d(64, 128, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.LeakyReLU(True),\n",
        "          nn.Conv2d(128, 256, 3, stride=2, padding = 1),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.LeakyReLU(True)\n",
        "        # nn.Conv2d(512, 1024, 3, stride=2, padding = 1),\n",
        "        # nn.BatchNorm2d(1024),\n",
        "        # nn.LeakyReLU(True)\n",
        "        )\n",
        "\n",
        "        ### Flatten layer\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        # ### Linear section\n",
        "        # self.encoder_lin = nn.Sequential(\n",
        "        #     nn.Linear(65536, 4096),\n",
        "        #     nn.ReLU(True),\n",
        "        #     nn.Linear(4096, 1024)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_cnn(x)\n",
        "        x = self.flatten(x)\n",
        "        # x = self.encoder_lin(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoded_space_dim):\n",
        "        super().__init__()\n",
        "        # self.decoder_lin = nn.Sequential(\n",
        "        #     nn.Linear(1024, 4096),\n",
        "        #     nn.ReLU(True),\n",
        "        #     nn.Linear(4096, 65536),\n",
        "        #     nn.ReLU(True)\n",
        "        # )\n",
        "\n",
        "        self.unflatten = nn.Unflatten(dim=1,\n",
        "        unflattened_size=(256, 2, 2))\n",
        "\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.decoder_lin(x)\n",
        "        x = self.unflatten(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vvxpgf9a8uY"
      },
      "outputs": [],
      "source": [
        "### Define the loss function\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "### Define an optimizer (both for the encoder and the decoder!)\n",
        "lr= 0.0001\n",
        "\n",
        "### Set the random seed for reproducible results\n",
        "torch.manual_seed(0)\n",
        "\n",
        "### Initialize the two networks\n",
        "d = 1024\n",
        "\n",
        "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
        "encoder = Encoder(encoded_space_dim=d)\n",
        "decoder = Decoder(encoded_space_dim=d)\n",
        "params_to_optimize = [\n",
        "    {'params': encoder.parameters()},\n",
        "    {'params': decoder.parameters()}\n",
        "]\n",
        "\n",
        "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
        "\n",
        "# Check if the GPU is available\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "\n",
        "# Move both the encoder and the decoder to the selected device\n",
        "encoder.to(device)\n",
        "decoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shZvCPJBhn3G"
      },
      "outputs": [],
      "source": [
        "### Training function\n",
        "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
        "    # Set train mode for both the encoder and the decoder\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = []\n",
        "    n = []\n",
        "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
        "    for image_batch in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
        "        # Move tensor to the proper device\n",
        "        image_batch = image_batch.to(device)\n",
        "        # Encode data\n",
        "        encoded_data = encoder(image_batch)\n",
        "        # Decode data\n",
        "        decoded_data = decoder(encoded_data)\n",
        "        # Evaluate loss\n",
        "        loss = loss_fn(decoded_data, image_batch)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        n.append(encoded_data)\n",
        "        # Print batch loss\n",
        "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
        "        train_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "    return np.mean(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x6BL-GdqCIV"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "diz_loss = {'train_loss':[]}\n",
        "final_l = []\n",
        "for epoch in range(num_epochs):\n",
        "   train_loss =train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
        "   final_l.append(train_loss)\n",
        "   diz_loss['train_loss'].append(train_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU0TtWmNE7hQ"
      },
      "outputs": [],
      "source": [
        "a = np.array(final_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcftGbLZTvou"
      },
      "outputs": [],
      "source": [
        "# xpoints = [i for i in range(1200)]\n",
        "ypoints = final_l\n",
        "# plt.plot(ypoints)\n",
        "plt.figure()\n",
        "# plt.plot(final_l)\n",
        "plt.title('Loss of CAE on Training Data')\n",
        "plt.plot(ypoints)\n",
        "plt.xlabel('number of epoch')\n",
        "plt.ylabel('Loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMEhjo2wtT5H"
      },
      "outputs": [],
      "source": [
        "# xpoints = [i for i in range(1200)]\n",
        "ypoints = final_l\n",
        "plt.plot(ypoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksE7DaGtpaYV"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"final_l.csv\", final_l, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvzm79rIXO_q"
      },
      "outputs": [],
      "source": [
        "output_encoder = np.zeros((6000,1024))\n",
        "# loss_test = []\n",
        "for i , x in enumerate(train_loader):\n",
        "  z = encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_encoder[i*200:(i+1)*200] = z\n",
        "  # print(z.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shii1oQpZ-1k"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "output_encoder_test = np.zeros((50,1024))\n",
        "for i , x in enumerate(test_loader):\n",
        "  z = encoder(x.to(device))\n",
        "  z = z.to('cpu').detach().numpy()\n",
        "  output_encoder_test[i*200:(i+1)*200] = z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq1jIK08aK_4"
      },
      "outputs": [],
      "source": [
        "print(output_encoder_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku3Rsa4eRCjs"
      },
      "source": [
        "# **8. Training shape decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDzavjzfDeV2"
      },
      "outputs": [],
      "source": [
        "#shape decoder model\n",
        "\n",
        "\n",
        "print('Training shape decoder:')\n",
        "#sp_decoder, sp_imgs, raw_imgs = decoding_shapes(train_lvc, train_imgs, test_lvc, test_imgs, output_size=32, n_epochs=101, batch_size=10, lr=0.0006)\n",
        "sp_decoder_v1, sp_imgs_v1, rand_id1 = decoding_shapes(fmri_train_v1, output_encoder, fmri_test_v1, output_encoder_test, output_size=32, n_epochs=600, batch_size=50, lr=0.000005)\n",
        "sp_decoder_v2, sp_imgs_v2, rand_id2 = decoding_shapes(fmri_train_v2, output_encoder, fmri_test_v2, output_encoder_test, output_size=32, n_epochs=600, batch_size=50, lr=0.000005)\n",
        "sp_decoder_v3, sp_imgs_v3, rand_id3 = decoding_shapes(fmri_train_v3, output_encoder, fmri_test_v3, output_encoder_test, output_size=32, n_epochs=600, batch_size=50, lr=0.000005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sIzb4NRlowR"
      },
      "outputs": [],
      "source": [
        "# raw_imgs_v1 = np.concatenate([patch_train_imgs, patch_aug_imgs])\n",
        "raw_imgs_v1 = np.concatenate([patch_train_imgs, patch_test_imgs])\n",
        "newSize = 32\n",
        "raw_imgs_v2 = np.zeros((6050,32,32))\n",
        "for i in range(6050):\n",
        "      raw_imgs_v2[i,:,:] = cv2.resize(raw_imgs_v1[i,:,:], dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "raw_imgs_v1 = raw_imgs_v2\n",
        "raw_imgs_v3 = raw_imgs_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIZ0QAjfKNTJ"
      },
      "outputs": [],
      "source": [
        "for i in range(50):\n",
        "  print(raw_imgs_v1[i].min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uagaghde_8Z"
      },
      "source": [
        "**`Save Shape decoder model`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx7quRhIfGPY"
      },
      "outputs": [],
      "source": [
        "output_dict1 = {\"sp_imgs_1\":sp_imgs_v1, \"rand_id1\": rand_id1 }\n",
        "#, \"rand_id1\": rand_id1\n",
        "torch.save(output_dict1,\"/content/drive/MyDrive/thesis/shape decoder model/output_dict1.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP-CE4_ufHEO"
      },
      "outputs": [],
      "source": [
        "output_dict2 = {\"sp_imgs_2\":sp_imgs_v2, \"rand_id2\": rand_id2}\n",
        "torch.save(output_dict2,\"/content/drive/MyDrive/thesis/shape decoder model/output_dict2.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQaBY_3IfN0c"
      },
      "outputs": [],
      "source": [
        "output_dict3 = {\"sp_imgs_3\":sp_imgs_v3, \"rand_id3\": rand_id3}\n",
        "torch.save(output_dict3,\"/content/drive/MyDrive/thesis/shape decoder model/output_dict3.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H3km5hnfQGs"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/thesis/shape decoder model\n",
        "torch.save(sp_decoder_v1.state_dict(), 'sp_decoder_v1.pth')\n",
        "torch.save(sp_decoder_v2.state_dict(), 'sp_decoder_v2.pth')\n",
        "torch.save(sp_decoder_v3.state_dict(), 'sp_decoder_v3.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ij-kWSbfUe0"
      },
      "source": [
        "**`Loading Shape decoder`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnGJL3kafvq0"
      },
      "outputs": [],
      "source": [
        "load_dict_1 = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/output_dict1.pth\")\n",
        "load_dict_2 = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/output_dict2.pth\")\n",
        "load_dict_3 = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/output_dict3.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-PJX_P6fygn"
      },
      "outputs": [],
      "source": [
        "sp_imgs_v1 = load_dict_1[\"sp_imgs_1\"]\n",
        "sp_imgs_v2 = load_dict_2[\"sp_imgs_2\"]\n",
        "sp_imgs_v3 = load_dict_3[\"sp_imgs_3\"]\n",
        "\n",
        "# raw_imgs_v1 = load_dict_1[\"raw_imgs_1\"]\n",
        "# raw_imgs_v2 = load_dict_2[\"raw_imgs_2\"]\n",
        "# raw_imgs_v3 = load_dict_3[\"raw_imgs_3\"]\n",
        "\n",
        "rand_id1 = load_dict_1[\"rand_id1\"]\n",
        "rand_id2 = load_dict_2[\"rand_id2\"]\n",
        "rand_id3 = load_dict_3[\"rand_id3\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAakgKcNf8pU"
      },
      "outputs": [],
      "source": [
        "fmri = np.concatenate([fmri_train_v1, fmri_test_v1])\n",
        "fmri_size = fmri.shape[1]\n",
        "latent_dim = 1024\n",
        "sp_decoder_v1 = Decoder_sh(fmri_size,latent_dim)\n",
        "sp_decoder_v1.to(device)\n",
        "sp_decoder_v1.load_state_dict(torch.load('/content/drive/MyDrive/thesis/shape decoder model/sp_decoder_v1.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FJDx8ijf_04"
      },
      "outputs": [],
      "source": [
        "fmri = np.concatenate([fmri_train_v2, fmri_test_v2])\n",
        "fmri_size = fmri.shape[1]\n",
        "latent_dim = 1024\n",
        "sp_decoder_v2 = Decoder_sh(fmri_size,latent_dim)\n",
        "sp_decoder_v2.to(device)\n",
        "sp_decoder_v2.load_state_dict(torch.load('/content/drive/MyDrive/thesis/shape decoder model/sp_decoder_v2.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAs03SVsgBxF"
      },
      "outputs": [],
      "source": [
        "fmri = np.concatenate([fmri_train_v3, fmri_test_v3])\n",
        "fmri_size = fmri.shape[1]\n",
        "latent_dim = 1024\n",
        "sp_decoder_v3 = Decoder_sh(fmri_size,latent_dim)\n",
        "sp_decoder_v3.to(device)\n",
        "sp_decoder_v3.load_state_dict(torch.load('/content/drive/MyDrive/thesis/shape decoder model/sp_decoder_v3.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1bHfsrWgwZw"
      },
      "source": [
        "**`Plot Reconstructed Images`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAyNJ8X_OfpF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data = raw_imgs_v1[1]\n",
        "# data = np.transpose(data)\n",
        "img = np.reshape(data, (32, 32))\n",
        "matplotlib.pyplot.imshow(img, cmap = 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjX2cBekQRs_"
      },
      "outputs": [],
      "source": [
        "for i in range(0,50):\n",
        "  print('reconstructed image from V1')\n",
        "  matplotlib.pyplot.imshow(patch_test_imgs[i], cmap = 'gray')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cORI1uRwGRY8"
      },
      "outputs": [],
      "source": [
        "#plot images\n",
        "\n",
        "# # matplotlib.pyplot.imshow(outPut_test[40,:,:])\n",
        "# # plt.show()\n",
        "for i in range(6000,6050):\n",
        "  print('reconstructed image from V1')\n",
        "  matplotlib.pyplot.imshow(raw_imgs_v1[i], cmap = 'gray')\n",
        "  plt.show()\n",
        "  # print('reconstructed image from V2')\n",
        "  # matplotlib.pyplot.imshow(sp_imgs_v2[i], cmap = 'gray')\n",
        "  # plt.show()\n",
        "  # print('reconstructed image from V3')\n",
        "  # matplotlib.pyplot.imshow(sp_imgs_v3[i], cmap = 'gray')\n",
        "  # # plt.show()\n",
        "  # print('raw image %d'%i)\n",
        "  # matplotlib.pyplot.imshow(np.transpose(raw_imgs_v1[i]), cmap = 'gray')\n",
        "  # plt.show()\n",
        "  print('reconstructed image from V1 + V2 + v3')\n",
        "  matplotlib.pyplot.imshow(1/3 * sp_imgs_v1[i]+ 1/3 * sp_imgs_v2[i]+ 1/3 * sp_imgs_v3[i], cmap = 'gray')\n",
        "  plt.show()\n",
        "\n",
        "# print(\"reconstructed image\")\n",
        "\n",
        "# matplotlib.pyplot.imshow(sp_imgs_v1[9])\n",
        "# plt.show()\n",
        "# print(\"real image\")\n",
        "# matplotlib.pyplot.imshow(raw_imgs_v1[9])\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5ZVlEf4dVWU"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.pyplot.imshow(sp_imgs_v1[1])\n",
        "plt.show()\n",
        "matplotlib.pyplot.imshow(sp_imgs_v2[1])\n",
        "plt.show()\n",
        "matplotlib.pyplot.imshow(sp_imgs_v3[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l8mzfyvS0pm"
      },
      "outputs": [],
      "source": [
        "# ordering\n",
        "import matplotlib\n",
        "# new_raw_v1 = np.zeros(raw_imgs_v1.shape)\n",
        "new_sp_v1 = np.zeros(sp_imgs_v1.shape)\n",
        "\n",
        "for id,i in enumerate(rand_id1):\n",
        "  # print(id)\n",
        "  # print(i)\n",
        "  # new[i] = t_fmri[id]\n",
        "  # new_raw_v1[i] = raw_imgs_v1[id]\n",
        "  new_sp_v1[i] = sp_imgs_v1[id]\n",
        "\n",
        "\n",
        "# print(new_raw_v1.shape)\n",
        "# matplotlib.pyplot.imshow(new_raw_v1[0])\n",
        "# plt.show()\n",
        "\n",
        "# new_raw_v2 = np.zeros(raw_imgs_v2.shape)\n",
        "new_sp_v2 = np.zeros(sp_imgs_v2.shape)\n",
        "for id,i in enumerate(rand_id2):\n",
        "  # print(id)\n",
        "  # print(i)\n",
        "  # new[i] = t_fmri[id]\n",
        "  # new_raw_v2[i] = raw_imgs_v2[id]\n",
        "  new_sp_v2[i] = sp_imgs_v2[id]\n",
        "# matplotlib.pyplot.imshow(new_raw_v2[0])\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# new_raw_v3 = np.zeros(raw_imgs_v3.shape)\n",
        "new_sp_v3 = np.zeros(sp_imgs_v3.shape)\n",
        "for id,i in enumerate(rand_id3):\n",
        "  # print(id)\n",
        "  # print(i)\n",
        "  # new[i] = t_fmri[id]\n",
        "  # new_raw_v3[i] = raw_imgs_v3[id]\n",
        "  new_sp_v3[i] = sp_imgs_v3[id]\n",
        "\n",
        "# matplotlib.pyplot.imshow(new_raw_v3[0])\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# new_raw_v1[6000:6050] = raw_imgs_v1[6000:6050]\n",
        "# new_raw_v2[6000:6050] = raw_imgs_v2[6000:6050]\n",
        "# new_raw_v3[6000:6050] = raw_imgs_v3[6000:6050]\n",
        "\n",
        "new_sp_v1[6000:6050] = sp_imgs_v1[6000:6050]\n",
        "new_sp_v2[6000:6050] = sp_imgs_v2[6000:6050]\n",
        "new_sp_v3[6000:6050] = sp_imgs_v3[6000:6050]\n",
        "\n",
        "# raw_imgs_v1 = new_raw_v1\n",
        "# raw_imgs_v2 = new_raw_v2\n",
        "# raw_imgs_v3 = new_raw_v3\n",
        "\n",
        "sp_imgs_v1 = new_sp_v1\n",
        "sp_imgs_v2 = new_sp_v2\n",
        "sp_imgs_v3 = new_sp_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh-p8CZo8As9"
      },
      "source": [
        "# **9. Linear Layer for Aggregation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBKaX9vCBEfG"
      },
      "outputs": [],
      "source": [
        "raw_imgs_v2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L36n0imxQ5CF"
      },
      "outputs": [],
      "source": [
        "newSize = 32\n",
        "raw_imgs_v2 = np.zeros((6050,32,32))\n",
        "for i in range(6050):\n",
        "      raw_imgs_v2[i,:,:] = cv2.resize(raw_imgs_v1[i,:,:], dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "raw_imgs_v1 = raw_imgs_v2\n",
        "raw_imgs_v3 = raw_imgs_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4U6qSFlfDNf"
      },
      "outputs": [],
      "source": [
        "print(raw_imgs_v3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKRiFDYf8oWc"
      },
      "outputs": [],
      "source": [
        "#Linear\n",
        "\n",
        "#train model\n",
        "import torch\n",
        "torch.manual_seed(1)\n",
        "t_loss = []\n",
        "t1_loss =[]\n",
        "for ix in range(10):\n",
        "  for iy in range(32):\n",
        "    train_set = CustomDataset(patch_imgs = raw_imgs_v1[0:6000], sp_imgs_v1 = sp_imgs_v1[0:6000,:,:],sp_imgs_v2 = sp_imgs_v2[0:6000,:,:], sp_imgs_v3 = sp_imgs_v3[0:6000,:,:], pixel = (ix,iy))\n",
        "    trainloader = DataLoader(train_set, batch_size = 100, shuffle= False)\n",
        "    result = Aggregation()\n",
        "    b = torch.tensor([1/3 , 1/3 , 1/3])\n",
        "    b = torch.unsqueeze(b , dim = 0)\n",
        "    result.fc.weight = nn.Parameter(b)\n",
        "    result.to(device)\n",
        "    result_loss = nn.MSELoss()\n",
        "    result_optimizer = torch.optim.Adam(params = result.parameters(), lr = 0.0001)\n",
        "\n",
        "    for i in range(120):\n",
        "      total_loss = AverageMeter()\n",
        "      result.train()\n",
        "\n",
        "      for x,y in trainloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        ypred = result(x)\n",
        "        m_loss = result_loss(y,ypred)\n",
        "        m_loss.backward()\n",
        "        result_optimizer.step()\n",
        "        result_optimizer.zero_grad()\n",
        "        total_loss.update(m_loss.item())\n",
        "        # t_loss.append(total_loss)\n",
        "      #save Linear model\n",
        "\n",
        "      print(f\"pixel: ({ix, iy}), epoch:{i},loss: {total_loss.avg}\")\n",
        "      t_loss.append(total_loss.avg)\n",
        "      t1_loss.append(t_loss)\n",
        "\n",
        "      t_loss = []\n",
        "    path = f\"/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_{ix}_{iy}.pt\"\n",
        "    torch.save(result.state_dict(), path)\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhUXtROfAnWM"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "# plt.plot(final_l)\n",
        "plt.title('Loss of Base Decoder(V3) on Test Data')\n",
        "plt.plot(t1_loss.avg)\n",
        "plt.xlabel('number of epoch * number of batch')\n",
        "plt.ylabel('L1 loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4tyLId9__yq"
      },
      "outputs": [],
      "source": [
        "#Linear\n",
        "#train model\n",
        "loss_t = []\n",
        "temp = []\n",
        "final_loss = []\n",
        "for ix in range(10,20):\n",
        "  for iy in range(32):\n",
        "\n",
        "    train_set = CustomDataset(patch_imgs = raw_imgs_v1[0:6000], sp_imgs_v1 = sp_imgs_v1[0:6000,:,:],sp_imgs_v2 = sp_imgs_v2[0:6000,:,:], sp_imgs_v3 = sp_imgs_v3[0:6000,:,:], pixel = (ix,iy))\n",
        "    trainloader = DataLoader(train_set, batch_size = 100, shuffle= False)\n",
        "    result = Aggregation()\n",
        "    b = torch.tensor([1/3 , 1/3 , 1/3])\n",
        "    b = torch.unsqueeze(b , dim = 0)\n",
        "    result.fc.weight = nn.Parameter(b)\n",
        "    result.to(device)\n",
        "    result_loss = nn.MSELoss()\n",
        "    result_optimizer = torch.optim.Adam(params = result.parameters(), lr = 0.0001)\n",
        "\n",
        "    for i in range(120):\n",
        "\n",
        "      total_loss = AverageMeter()\n",
        "      result.train()\n",
        "      temp = []\n",
        "\n",
        "      for x,y in trainloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        ypred = result(x)\n",
        "        m_loss = result_loss(y,ypred)\n",
        "        m_loss.backward()\n",
        "        result_optimizer.step()\n",
        "        result_optimizer.zero_grad()\n",
        "        total_loss.update(m_loss.item())\n",
        "        temp.append(m_loss.item())\n",
        "      final_loss.append(np.average(temp))\n",
        "\n",
        "      #save Linear model\n",
        "      print(f\"pixel: ({ix, iy}), epoch:{i},loss: {total_loss.avg}\")\n",
        "\n",
        "    path = f\"/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_{ix}_{iy}.pt\"\n",
        "    torch.save(result.state_dict(), path)\n",
        "    print(\"-\"*50)\n",
        "plt.plot(final_loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJYAEdidACcU"
      },
      "outputs": [],
      "source": [
        "#Linear\n",
        "\n",
        "#train model\n",
        "\n",
        "\n",
        "for ix in range(20,32):\n",
        "  for iy in range(32):\n",
        "    train_set = CustomDataset(patch_imgs = raw_imgs_v1[0:6000], sp_imgs_v1 = sp_imgs_v1[0:6000,:,:],sp_imgs_v2 = sp_imgs_v2[0:6000,:,:], sp_imgs_v3 = sp_imgs_v3[0:6000,:,:], pixel = (ix,iy))\n",
        "    trainloader = DataLoader(train_set, batch_size = 100, shuffle= False)\n",
        "    result = Aggregation()\n",
        "    b = torch.tensor([1/3 , 1/3 , 1/3])\n",
        "    b = torch.unsqueeze(b , dim = 0)\n",
        "    result.fc.weight = nn.Parameter(b)\n",
        "    result.to(device)\n",
        "    result_loss = nn.MSELoss()\n",
        "    result_optimizer = torch.optim.Adam(params = result.parameters(), lr = 0.0001)\n",
        "\n",
        "    for i in range(120):\n",
        "      total_loss = AverageMeter()\n",
        "      result.train()\n",
        "\n",
        "      for x,y in trainloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        ypred = result(x)\n",
        "        m_loss = result_loss(y,ypred)\n",
        "        m_loss.backward()\n",
        "        result_optimizer.step()\n",
        "        result_optimizer.zero_grad()\n",
        "        total_loss.update(m_loss.item())\n",
        "      #save Linear model\n",
        "\n",
        "      print(f\"pixel: ({ix, iy}), epoch:{i},loss: {total_loss.avg}\")\n",
        "\n",
        "    path = f\"/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_{ix}_{iy}.pt\"\n",
        "    torch.save(result.state_dict(), path)\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTgzhY75-G5J"
      },
      "outputs": [],
      "source": [
        "#load Linear Models for train Phase\n",
        "outPut = np.zeros((6000,32,32))\n",
        "#outPut = outPut.to(device)\n",
        "for ix in range(32):\n",
        "  for iy in range(32):\n",
        "    train_set = CustomDataset(patch_imgs = raw_imgs_v1[0:6000], sp_imgs_v1 = sp_imgs_v1[0:6000,:,:],sp_imgs_v2 = sp_imgs_v2[0:6000,:,:], sp_imgs_v3 = sp_imgs_v3[0:6000,:,:], pixel = (ix,iy))\n",
        "    trainloader = DataLoader(train_set, batch_size = 6000, shuffle= False)\n",
        "    linear_model = Aggregation()\n",
        "    path = f\"/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_{ix}_{iy}.pt\"\n",
        "    linear_model.load_state_dict(torch.load(path))\n",
        "    #linear_model.to(device)\n",
        "    linear_model.eval()\n",
        "\n",
        "    for x,y in trainloader:\n",
        "      #x = x.to(device)\n",
        "      #y = y.to(device)\n",
        "      ypred = linear_model(x)\n",
        "\n",
        "    #ypred.cpu()\n",
        "    ypred_1 = ypred.squeeze()\n",
        "    outPut[:,ix,iy] = ypred_1.detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWy9LRRZ-JOV"
      },
      "outputs": [],
      "source": [
        "#Linear model for test Phase\n",
        "\n",
        "\n",
        "outPut_test = np.zeros((50,32,32))\n",
        "for ix in range(32):\n",
        "  for iy in range(32):\n",
        "    test_set = CustomDataset(patch_imgs = raw_imgs_v1[6000:6050], sp_imgs_v1 = sp_imgs_v1[6000:6050,:,:],sp_imgs_v2 = sp_imgs_v2[6000:6050,:,:], sp_imgs_v3 = sp_imgs_v3[6000:6050,:,:], pixel = (ix,iy))\n",
        "    testloader = DataLoader(test_set, batch_size = 50, shuffle= False)\n",
        "    linear_model = Aggregation()\n",
        "    path = f\"/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_{ix}_{iy}.pt\"\n",
        "    linear_model.load_state_dict(torch.load(path))\n",
        "    #linear_model.to(device)\n",
        "    linear_model.eval()\n",
        "\n",
        "    for x,y in testloader:\n",
        "      #x = x.to(device)\n",
        "      #y = y.to(device)\n",
        "      ypred = linear_model(x)\n",
        "\n",
        "    #ypred.cpu()\n",
        "    ypred_1 = ypred.squeeze()\n",
        "    outPut_test[:,ix,iy] = ypred_1.detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BurHZpdEUOD"
      },
      "outputs": [],
      "source": [
        "print('finish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UA2RjMc-NAo"
      },
      "outputs": [],
      "source": [
        "#check weights of models\n",
        "a = torch.load('/content/drive/MyDrive/thesis/linear_model_new_decoder/Linear_1_30.pt')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME_R_muc-Nrv"
      },
      "outputs": [],
      "source": [
        "#check max value of pixels in images\n",
        "import matplotlib\n",
        "for i in range(6000):\n",
        "  a = outPut[i,:,:].max()\n",
        "  print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvV6gjQH-Pgf"
      },
      "outputs": [],
      "source": [
        "#plot images\n",
        "import matplotlib\n",
        "plt.show()\n",
        "matplotlib.pyplot.imshow(outPut_test[0,:,:], cmap = 'gray')\n",
        "#plt.show()\n",
        "# matplotlib.pyplot.imshow(sp_imgs_v1[1200])\n",
        "# plt.show()\n",
        "# matplotlib.pyplot.imshow(sp_imgs_v2[1200])\n",
        "plt.show()\n",
        "matplotlib.pyplot.imshow(1/3 * sp_imgs_v1[6000]+ 1/3 * sp_imgs_v2[6000]+ 1/3 * sp_imgs_v3[6000], cmap = 'gray')\n",
        "plt.show()\n",
        "matplotlib.pyplot.imshow(raw_imgs_v1[6000], cmap = 'gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIJKBG93zTDF"
      },
      "source": [
        "# **RGB array of Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1OZcVRoyXqd"
      },
      "source": [
        "**Change RGB Images and Build Array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TCp8BzZRciq"
      },
      "outputs": [],
      "source": [
        "#select Training images that correspond to stimulusID\n",
        "import shutil\n",
        "%cd /content/\n",
        "# \"convert tsv file into dictioary\"\n",
        "tsv_file = open(\"/content/drive/MyDrive/Stimulus_excel/stimulus_NaturalImageTraining.tsv\")\n",
        "read_tsv = csv. reader(tsv_file, delimiter=\"\\t\")\n",
        "df = pd.DataFrame(read_tsv)\n",
        "df = df.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "df['label'] = df['label'].astype(float, errors = 'raise')\n",
        "train_labels = df[\"label\"]\n",
        "#train_labels = np.array(train_labels)\n",
        "print(train_labels.dtype)\n",
        "df.drop(['label','num'] , inplace=True, axis=1)\n",
        "\n",
        "dict_train = dict(zip(df.ID, df.Name))\n",
        "print(dict_train)\n",
        "nameStimulus = []\n",
        "# \"find ID's that correspond to Image name\"\n",
        "for ID in stimulusID:\n",
        "  #res = {sub['name'] : sub['age'] for ID in test_list}\n",
        "  res = {float(key) : dict_train[key] for key in dict_train}\n",
        "  convK = float(ID)\n",
        "  res = res[convK]\n",
        "  nameStimulus.append(res)\n",
        "\n",
        "\n",
        "print(nameStimulus)\n",
        "#directory_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "original_path = '/content/drive/MyDrive/thesis/data/images/demo1/original_imgs/'\n",
        "# original_path = '/content/drive/MyDrive/thesis/data/images/demo1/fff/'\n",
        "target_path = '/content/drive/MyDrive/thesis/data/images/demo1/new_original/'\n",
        "\n",
        "nameStimulus = nameStimulus[0:6000]\n",
        "new_name = 0\n",
        "for picture_name in nameStimulus:\n",
        "\n",
        "  new_original = os.path.join(original_path, picture_name + \".JPEG\")\n",
        "  if os.path.isfile(new_original):\n",
        "    new_target = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    shutil.copyfile(new_original, new_target)\n",
        "    #new_dir = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    #os.rename(file_path, new_dir)\n",
        "  new_original = \"\"\n",
        "  new_target = \"\"\n",
        "  new_name = int(new_name) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NABevcnIWbtj"
      },
      "outputs": [],
      "source": [
        "#select Test images that correspond to stimulusID\n",
        "import shutil\n",
        "%cd /content/\n",
        "# \"convert tsv file into dictioary\"\n",
        "test_file = open(\"/content/drive/MyDrive/Stimulus_excel/stimulus_NaturalImageTest.tsv\")\n",
        "test_tsv = csv. reader(test_file, delimiter=\"\\t\")\n",
        "df_test = pd.DataFrame(test_tsv)\n",
        "df_test = df_test.set_axis(['Name', 'ID','label','num'], axis=1, inplace=False)\n",
        "\n",
        "df_test['label'] = df_test['label'].astype(float, errors = 'raise')\n",
        "test_labels = df_test['label']\n",
        "df_test.drop(['label','num'] , inplace=True, axis=1)\n",
        "\n",
        "\n",
        "dict_test = dict(zip(df_test.ID, df_test.Name))\n",
        "#print(dict_test)\n",
        "\n",
        "nameStimulus = []\n",
        "# \"find ID's that correspond to Image name\"\n",
        "for ID in stimulusID_test:\n",
        "\n",
        "  res = {float(key) : dict_test[key] for key in dict_test}\n",
        "  convK = float(ID)\n",
        "  res = res[convK]\n",
        "  nameStimulus.append(res)\n",
        "\n",
        "#directory_path = '/content/drive/MyDrive/thesis/data/images/demo1/raw_imgs/'\n",
        "original_path = '/content/drive/MyDrive/thesis/data/images/demo1/original_imgs/'\n",
        "# original_path = '/content/drive/MyDrive/thesis/data/images/demo1/fff/'\n",
        "target_path = '/content/drive/MyDrive/thesis/data/images/demo1/new_original/'\n",
        "\n",
        "new_name = 6000\n",
        "nameStimulus = nameStimulus[0:50]\n",
        "for picture_name in nameStimulus:\n",
        "\n",
        "  new_original = os.path.join(original_path, picture_name + \".JPEG\")\n",
        "  if os.path.isfile(new_original):\n",
        "    new_target = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    shutil.copyfile(new_original, new_target)\n",
        "    #new_dir = os.path.join(target_path, str(new_name) + \".JPEG\")\n",
        "    #os.rename(file_path, new_dir)\n",
        "    new_original = \"\"\n",
        "    new_target = \"\"\n",
        "  else:\n",
        "    new_original = \"\"\n",
        "    new_target = \"\"\n",
        "  new_name = int(new_name) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpNtLBDExzpz"
      },
      "source": [
        "**LOAD RGB IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIhZuyvnoNYk"
      },
      "outputs": [],
      "source": [
        "import skimage.measure\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "\n",
        "newSize = 256\n",
        "pnew = []\n",
        "num = 0\n",
        "path = '/content/drive/MyDrive/thesis/data/images/demo1/new_original/'\n",
        "\n",
        "for i in range(6050):\n",
        "  real_imgs_rgb = plt.imread(path +'%d.JPEG' %i)\n",
        "  # print(real_imgs_rgb)\n",
        "  if len(real_imgs_rgb.shape) == 2:\n",
        "    real_imgs_rgb = cv2.cvtColor(real_imgs_rgb, cv2.COLOR_GRAY2RGB)\n",
        "  pnew.append(cv2.resize(real_imgs_rgb, (0,0),fx = 0.512 , fy = 0.512))\n",
        "  # print(pnew[i-1])\n",
        "  # print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOyCTjLf5-dV"
      },
      "outputs": [],
      "source": [
        "patch_imgs_rgb = np.array(pnew)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBMo0cpVLPMc"
      },
      "outputs": [],
      "source": [
        "A = []\n",
        "for i in range(250):\n",
        "  first = patch_imgs_rgb[i]\n",
        "  first = np.transpose(first,(2,0,1))\n",
        "\n",
        "  A.append(first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mhMHxwCBAAk"
      },
      "outputs": [],
      "source": [
        "RGB_imgs_1 = np.array(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHkGvJkjLWGe"
      },
      "outputs": [],
      "source": [
        "RGB_imgs_1 = torch.tensor(RGB_imgs_1 , dtype = torch.float32)\n",
        "RGB_imgs_1 = RGB_imgs_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjCJVm6aST1q"
      },
      "source": [
        "Save RGB Images into array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxt2R7PO5U6G"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "%cd '/content/drive/MyDrive/thesis/rgb_images/'\n",
        "for i  in range(1):\n",
        "  patch_one = RGB_imgs_1[num:num+250]\n",
        "  output_imgs_rgb = {\"patch_%d\"%i:patch_one}\n",
        "  torch.save(output_imgs_rgb,\"/content/drive/MyDrive/thesis/shape decoder model/output_imgs_rgb_%d.pth\" %i)\n",
        "  num = num +250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx52VGcuDVUs"
      },
      "outputs": [],
      "source": [
        "patch_one = RGB_imgs_1[6000:6050]\n",
        "output_imgs_rgb = {\"patch_test\":patch_one}\n",
        "torch.save(output_imgs_rgb,\"/content/drive/MyDrive/thesis/shape decoder model/output_imgs_rgb_test.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCrmwTj1SYHf"
      },
      "source": [
        "Load RGB Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gR_dfe0OyNh"
      },
      "outputs": [],
      "source": [
        "RGB_imgs = np.zeros((250,3,256,256))\n",
        "a = 0\n",
        "b = 250\n",
        "for i in range(1):\n",
        "  patch_imgs_rgb = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/output_imgs_rgb_%d.pth\" %i)\n",
        "\n",
        "  # print(type(patch_imgs_rgb[\"patch_0\"]))\n",
        "  first = patch_imgs_rgb[\"patch_%d\"%i]\n",
        "  first = first.cpu().data.numpy()\n",
        "  print(first)\n",
        "  # plt.imshow(first)\n",
        "  # first_1 = np.transpose(first,(0,1,2,3))\n",
        "  RGB_imgs[a:b, :, :, :] = first\n",
        "  a = a + 250\n",
        "  b = b + 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx0CtZepSag4"
      },
      "outputs": [],
      "source": [
        "RGB_imgs = torch.tensor(RGB_imgs , dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sflDDaM2hdLL"
      },
      "outputs": [],
      "source": [
        "RGB_imgs = RGB_imgs.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNaDheysW8sB"
      },
      "outputs": [],
      "source": [
        "print(RGB_imgs[0].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcb-ogABy48o"
      },
      "outputs": [],
      "source": [
        "real_b = RGB_imgs.cpu().data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ozskwhVuZKR"
      },
      "source": [
        "LOAD Test RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC-uf2tuua_t"
      },
      "outputs": [],
      "source": [
        "RGB_test = np.zeros((50,3,256,256))\n",
        "\n",
        "patch_imgs_rgb = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/output_imgs_rgb_test.pth\")\n",
        "\n",
        "first = patch_imgs_rgb[\"patch_test\"]\n",
        "print(first)\n",
        "first = np.transpose(first,(0,3,1,2))\n",
        "RGB_test[0:50, :, :, :] = first\n",
        "\n",
        "RGB_test = torch.tensor(RGB_test , dtype = torch.float32)\n",
        "RGB_test = RGB_test.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss1fgvEYUtO7"
      },
      "source": [
        "# **10. Saving unpooling Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrjzouGkK8xV"
      },
      "outputs": [],
      "source": [
        "newSize = 256\n",
        "raw_imgs_v2 = np.zeros((6050,256,256,3))\n",
        "for i in range(6050):\n",
        "      raw_imgs_v2[i,:,:] = cv2.resize(raw_imgs_v1[i,:,:], dsize = (newSize, newSize), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "raw_imgs_v1 = raw_imgs_v2\n",
        "raw_imgs_v3 = raw_imgs_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c71IP_05cqJZ"
      },
      "outputs": [],
      "source": [
        "raw_imgs_v1 = patch_imgs_rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5bY2aLMldA9"
      },
      "outputs": [],
      "source": [
        "raw_imgs_v2 = raw_imgs_v1\n",
        "raw_imgs_v3 = raw_imgs_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XELK86rIUvtx"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(0,1000):\n",
        "  a  = outPut[i]\n",
        "  # b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDZI9LL8WVoi"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAYnEp0u1H6_"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17bSyCzp8db8"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(1000,2000):\n",
        "  a  = outPut[i]\n",
        "  b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  # unpool_trainimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzCJrhBt61JW"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i+1000))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRD6BH2ZT7Ah"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IknFdGmA8kXb"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(2000,3000):\n",
        "  a  = outPut[i]\n",
        "  b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  # unpool_trainimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQeeaDilTzAc"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i+2000))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MfmdUC8T8oc"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxxEjHXQ8nTc"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(3000,4000):\n",
        "  a  = outPut[i]\n",
        "  b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  # unpool_trainimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8e5F9ecUdn-"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i+3000))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAoXp10qUo8k"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-IF1ZuB8qLe"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(4000,5000):\n",
        "  a  = outPut[i]\n",
        "  b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  # unpool_trainimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctYlfUsVUgAM"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i+4000))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkYmuMEXUntJ"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjk8XA5T8yX3"
      },
      "outputs": [],
      "source": [
        "#unpooling train data\n",
        "#unpool_spimages = []\n",
        "unpool_trainimages = []\n",
        "unpool_outPut = []\n",
        "for i in range(5000,6000):\n",
        "  a  = outPut[i]\n",
        "  b = raw_imgs_v2[i]\n",
        "  #c = outPut[i,:,:]\n",
        "  unpool_outPut.append(unpoolingAvg(a, 8, (256,256)))\n",
        "  # unpool_trainimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_trainimages.append(patch_imgs_rgb[i])\n",
        "  #unpool_outPut.append(unpoolingAvg(c, 8, (256,256)))\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_outPut[0])\n",
        "# plt.show()\n",
        "# #print(unpool_spimages[1])\n",
        "\n",
        "# matplotlib.pyplot.imshow(unpool_trainimages[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCShd7U4UiaC"
      },
      "outputs": [],
      "source": [
        "#save shape decoder outputs\n",
        "\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    im = unpool_outPut[i]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    # z = unpool_trainimages[i]\n",
        "    z = (np.array(unpool_trainimages))\n",
        "    raw_img = Image.fromarray(z[i])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    # print(i)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % (i+5000))\n",
        "    # matplotlib.pyplot.imshow(target)\n",
        "    # plt.show()\n",
        "#.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xn9C34rsa2y"
      },
      "outputs": [],
      "source": [
        "%reset_selective unpool_trainimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQlCqYg9WYae"
      },
      "outputs": [],
      "source": [
        "#unpooling test data\n",
        "unpool_testimages = []\n",
        "unpool_outPut_test = []\n",
        "for i in range(0,50):\n",
        "  b = raw_imgs_v2[i+6000]\n",
        "  c = outPut_test[i,:,:]\n",
        "  # unpool_testimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  unpool_testimages.append(patch_imgs_rgb[i+6000])\n",
        "  unpool_outPut_test.append(unpoolingAvg(c, 8, (256,256)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5H42K1dfiF1"
      },
      "outputs": [],
      "source": [
        "for i in range(6000, 6050):\n",
        "\n",
        "    im = unpool_outPut_test[i-6000]\n",
        "    im = (np.array(im) * 255)\n",
        "    im = Image.fromarray(im)\n",
        "    im = im.convert('RGB')\n",
        "    z = (np.array(unpool_testimages))\n",
        "    raw_img = Image.fromarray(z[i-6000])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    #display(raw_img)\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(im, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/val/%d.jpg' % i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxzZ9-PyJEa2"
      },
      "outputs": [],
      "source": [
        "print(\"done tonight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSmRtdgrac2m"
      },
      "outputs": [],
      "source": [
        "#unpooling Aug data\n",
        "unpool_augimages = []\n",
        "unpool_outPut_test = []\n",
        "for i in range(0,1200):\n",
        "  b = raw_imgs_v2[i+6000]\n",
        "  # c = outPut_test[i,:,:]\n",
        "  unpool_augimages.append(unpoolingAvg(b, 8, (256,256)))\n",
        "  # unpool_outPut_test.append(unpoolingAvg(c, 8, (256,256)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYyuQE_CX7FJ"
      },
      "outputs": [],
      "source": [
        "for i in range(6000, 7200):\n",
        "\n",
        "    # im = unpool_outPut_test[i-6000]\n",
        "    # im = (np.array(im) * 255)\n",
        "    # im = Image.fromarray(im)\n",
        "    # im = im.convert('RGB')\n",
        "    z = (np.array(unpool_augimages) * 255)\n",
        "    raw_img = Image.fromarray(z[i-6000])\n",
        "    raw_img = raw_img.convert('RGB')\n",
        "    target = Image.new('RGB', (256 * 2, 256))\n",
        "    target.paste(raw_img, (0, 0, 256, 256))\n",
        "    target.paste(raw_img, (256, 0, 512, 256))\n",
        "    target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "    target.save('/content/drive/MyDrive/thesis/data/images/demo1/samples/train/%d.jpg' % i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoW4H2DcYBzT"
      },
      "source": [
        "# **12.final shape decoder outputs without Linear Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCAFODCBX-7S"
      },
      "outputs": [],
      "source": [
        "outPut = np.zeros((6000,32,32))\n",
        "for i in range(6000):\n",
        "  outPut[i,:,:] = 1/3 * sp_imgs_v1[i]+ 1/3 * sp_imgs_v2[i]+ 1/3 * sp_imgs_v3[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMsoAkJFX_yn"
      },
      "outputs": [],
      "source": [
        "outPut_test = np.zeros((50,32,32))\n",
        "for i in range(6000,6050):\n",
        "  outPut_test[i-6000,:,:] = 1/3 * sp_imgs_v1[i]+ 1/3 * sp_imgs_v2[i]+ 1/3 * sp_imgs_v3[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyxNP7CBblDK"
      },
      "source": [
        "# **13. Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vobIcbpRDh9g"
      },
      "outputs": [],
      "source": [
        "n_epochs = 15 #ghablan 10 bood\n",
        "batch_size = 50\n",
        "lr = 0.0002\n",
        "b1 = 0.9\n",
        "b2 = 0.999\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3\n",
        "dataset_name = '69digits'\n",
        "interval = 2\n",
        "test_sample_num = 50\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "# Loss functions\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_pixelwise = torch.nn.MSELoss()\n",
        "criteirion_contour = torch.nn.MSELoss()\n",
        "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
        "lambda_pixel = 150\n",
        "\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (3, img_height // 2 **4 , img_width // 2 ** 4)\n",
        "\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = GeneratorUNet()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_pixelwise.cuda()\n",
        "    criteirion_contour.cuda()\n",
        "\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr = lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.SGD(discriminator.parameters(),  lr = lr)\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=3, gamma=0.9)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=3, gamma=0.9)\n",
        "\n",
        "\n",
        "# Configure dataloaders\n",
        "transforms_ = [\n",
        "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "\n",
        "# training set\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\"/content/drive/MyDrive/thesis/data/images/demo1/samples/\", transforms_=transforms_, mode='train'),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "# validation set\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(\"/content/drive/MyDrive/thesis/data/images/demo1/samples/\", transforms_=transforms_, mode=\"val\"),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Tensor type\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "print('Load semantic features:')\n",
        "semantic_vecs = torch.load('/content/drive/MyDrive/thesis/data/sm_features/demo1/semantics')\n",
        "# aug_train_new = torch.Tensor(aug_train)\n",
        "train_semantic_vec = semantic_vecs[0:6000]\n",
        "# train_semantic_vec = aug_train_new\n",
        "test_semantic_vec = semantic_vecs[6000:6050]\n",
        "train_semantic_vec = train_semantic_vec.type(Tensor)\n",
        "test_semantic_vec = test_semantic_vec.type(Tensor)\n",
        "prev_time = time.time()\n",
        "\n",
        "generator_loss = []\n",
        "discriminator_loss = []\n",
        "GAN_loss = []\n",
        "epoch_array = []\n",
        "batch = []\n",
        "k = 0\n",
        "for epoch in range(0, n_epochs):\n",
        "    scheduler_D.step()\n",
        "    scheduler_G.step()\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # Model inputs\n",
        "        real_A = batch[\"B\"].type(Tensor)   #  contours\n",
        "        real_B = batch[\"A\"].type(Tensor)   #  real images\n",
        "        # if k<= 5950:\n",
        "          # real_B = RGB_imgs_1[k:k+50]\n",
        "        # patch_imgs_rgb\n",
        "        # Adversarial ground truths\n",
        "        #normalization real A\n",
        "        # a = real_A.cpu().detach().numpy()\n",
        "        # real_A = cv2.normalize(a, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "        # b = a[:,:,0]\n",
        "        # real_A = torch.from_numpy(b).float().to(device)\n",
        "        #norm real B\n",
        "        # a_b = real_B.cpu().detach().numpy()\n",
        "        # a_b = a_b[0,:,:]\n",
        "        # real_B = cv2.normalize(a_b, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "        # real_B = torch.from_numpy(real_B).float().to(device)\n",
        "        valid = Tensor(np.ones((real_B.size(0), *patch)))\n",
        "        fake = Tensor(np.zeros((real_B.size(0), *patch)))\n",
        "        #Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = generator(real_A, train_semantic_vec[i*batch_size:(i+1)*batch_size])\n",
        "        print(train_semantic_vec.shape)\n",
        "        out_gen = fake_B\n",
        "        # fake_B = generator(real_A)\n",
        "        # test_a = fake_B\n",
        "        pred_fake = discriminator(fake_B, real_A)\n",
        "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
        "        # # Pixel-wise loss\n",
        "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
        "        # Total loss\n",
        "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "        #save images into folder\n",
        "        if i == 10:\n",
        "          # for l in range(50):\n",
        "          X_test = fake_B[5]\n",
        "          a = X_test.cpu().detach().numpy()\n",
        "          x_test = np.array(np.transpose(a, (1,2,0)))\n",
        "          image_norm = cv2.normalize(x_test, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "          plt.imshow((image_norm*255).astype(np.uint8))\n",
        "          plt.savefig('/content/drive/MyDrive/thesis/test-gen/reconstructed'+ str(epoch) + '_' + str(5))\n",
        "            # X_train = real_B[l]\n",
        "            # a_train = X_train.cpu().detach().numpy()\n",
        "            # x_train = np.array(np.transpose(a_train, (1,2,0)))\n",
        "            # image_norm_train = cv2.normalize(x_train, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "            # plt.imshow((image_norm_train*255).astype(np.uint8))\n",
        "            # plt.savefig('/content/drive/MyDrive/thesis/gen_out_200/train_imgs'+ str(epoch) + '_' + str(l))\n",
        "\n",
        "\n",
        "        #  Train Discriminator\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = discriminator(real_B, real_A)\n",
        "        loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "        # Fake loss\n",
        "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
        "        print(pred_fake.shape)\n",
        "        loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        #  Log Progress\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds = batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "        #Plot\n",
        "\n",
        "        generator_loss.append(loss_G.item())\n",
        "        discriminator_loss.append(loss_D.item())\n",
        "        GAN_loss.append(loss_GAN.item())\n",
        "        epoch_array.append(epoch)\n",
        "\n",
        "        k =  k + 1\n",
        "        print(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f] ETA: %s\"\n",
        "            % (\n",
        "                epoch,\n",
        "                n_epochs,\n",
        "                i,\n",
        "                len(dataloader),\n",
        "                loss_D.item(),\n",
        "                loss_G.item(),\n",
        "                loss_pixel.item(),\n",
        "                loss_GAN.item(),\n",
        "                time_left,\n",
        "            )\n",
        "        )\n",
        "#plot\n",
        "# Importing libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Using Numpy to create an array X\n",
        "X = [i for i in range(len(dataloader)*n_epochs)]\n",
        "\n",
        "# Assign variables to the y axis part of the curve\n",
        "y = generator_loss\n",
        "z = discriminator_loss\n",
        "\n",
        "# Plotting both the curves simultaneously\n",
        "plt.plot(X, y, color='r', label='Gan loss')\n",
        "plt.figure()\n",
        "plt.plot(X, z, color='g', label='discriminator loss')\n",
        "# To load the display window\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxm5sNNJH5Wf"
      },
      "outputs": [],
      "source": [
        "criterion_GAN = torch.nn.MSELoss()\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (1, img_height // 2 **4 , img_width // 2 ** 4)\n",
        "valid = Tensor(np.ones((real_B.size(0), *patch)))\n",
        "fake = Tensor(np.zeros((real_B.size(0), *patch)))\n",
        "# Real loss\n",
        "pred_real = discriminator(real_B, real_A)\n",
        "loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "# Fake loss\n",
        "pred_fake = discriminator(fake_B.detach(), real_A)\n",
        "loss_fake = criterion_GAN(pred_fake, fake)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8KWBhTR4AXv"
      },
      "source": [
        "**Save Generator **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2T1C_fF56tM"
      },
      "outputs": [],
      "source": [
        "output_dict5 = {\"fake_B\":fake_B}\n",
        "torch.save(output_dict5,\"/content/drive/MyDrive/thesis/shape decoder model/generator.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNPs6MieHPlf"
      },
      "outputs": [],
      "source": [
        "a = real_A.cpu().detach().numpy()\n",
        "a10 = np.array(np.transpose(a[1], (1,2,0)))\n",
        "# plt.imshow(np.array(a10*255).astype(np.uint8))\n",
        "print(a10[:,:,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csfSY1HVkwmk"
      },
      "outputs": [],
      "source": [
        "generator_one = torch.load(\"/content/drive/MyDrive/thesis/shape decoder model/generator.pth\")\n",
        "fake_B = generator_one[\"fake_B\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSyqDZZHvFUL"
      },
      "outputs": [],
      "source": [
        "generator = GeneratorUNet()\n",
        "discriminator = Discriminator()\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "if cuda:\n",
        "    generator = generator.cuda()\n",
        "    # discriminator = discriminator.cuda()\n",
        "    # criterion_GAN.cuda()\n",
        "    # criterion_pixelwise.cuda()\n",
        "    # criteirion_contour.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff7BKVvFlA6D"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200 #ghablan 10 bood\n",
        "batch_size = 50\n",
        "lr = 0.0002\n",
        "b1 = 0.9\n",
        "b2 = 0.999\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3\n",
        "dataset_name = '69digits'\n",
        "interval = 2\n",
        "test_sample_num = 50\n",
        "transforms_ = [\n",
        "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(\"/content/drive/MyDrive/thesis/data/images/demo1/samples/\", transforms_=transforms_, mode=\"val\"),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ogo4k0Dbl8iB"
      },
      "outputs": [],
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "semantic_vecs = torch.load('/content/drive/MyDrive/thesis/data/sm_features/demo1/semantics')\n",
        "# aug_train_new = torch.Tensor(aug_train)\n",
        "train_semantic_vec = semantic_vecs[0:6000]\n",
        "# train_semantic_vec = aug_train_new\n",
        "test_semantic_vec = semantic_vecs[6000:6050]\n",
        "train_semantic_vec = train_semantic_vec.type(Tensor)\n",
        "test_semantic_vec = test_semantic_vec.type(Tensor)\n",
        "prev_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeQ-gGkh6WOi"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from SSIM_PIL import compare_ssim\n",
        "from PIL import Image\n",
        "from sklearn.metrics import jaccard_score\n",
        "k = 0\n",
        "s = 0\n",
        "e = 50\n",
        "fakex = []\n",
        "realx = []\n",
        "i = 0\n",
        "SSIM_rec = np.array([])\n",
        "SSIM_Random = np.array([])\n",
        "value_list = np.array([])\n",
        "similarity_array = np.array([])\n",
        "value_list_random = np.array([])\n",
        "# my_rho = np.corrcoef(x_simple, y_simple)************************************************ COrrelation Coefficient\n",
        "h = 0\n",
        "# for i in range(0,5):\n",
        "for j, batch in enumerate(val_dataloader):\n",
        "  if j == 0:\n",
        "      plt.figure()\n",
        "      real_A = batch[\"B\"].type(Tensor)#contours\n",
        "      real_B = batch[\"A\"].type(Tensor)#real images\n",
        "      fake_B = generator(real_A, test_semantic_vec[h:h+50]) #reconstructed images\n",
        "      fake_B = fake_B.cpu().data\n",
        "      fake_B = np.asarray(fake_B)\n",
        "      real_test_one = fake_B\n",
        "      real_B = real_B.cpu().data\n",
        "      # real_b = RGB_test.cpu().data\n",
        "      # real_B = np.asarray(real_B)\n",
        "      fakex = fake_B\n",
        "      realx = real_B\n",
        "      h = h + 50\n",
        "      if h >= 100:\n",
        "        break\n",
        "      for i in range(50):\n",
        "          v = i+h-50\n",
        "          print('**********%d*********'%v)\n",
        "        #reconstructed image\n",
        "          fimg = fake_B[i]\n",
        "          fimg = np.array(np.transpose(fimg, (1,2,0)))\n",
        "          fimg = cv2.normalize(fimg, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "          fimg = (np.array(fimg*255)).astype(np.uint8)\n",
        "          # fimg = Image.fromarray(fimg)\n",
        "        #real image\n",
        "          rimg = realx[i]\n",
        "          rimg = np.array(np.transpose(rimg, (1,2,0)))\n",
        "          rimg = cv2.normalize(rimg, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "          rimg = (np.array(rimg*255)).astype(np.uint8)\n",
        "          # rimg = Image.fromarray(rimg)\n",
        "        #random reconstructed image\n",
        "          m = random.randint(0,49)\n",
        "          while m == i :\n",
        "            m = random.randint(0,49)\n",
        "          rand_fake = fake_B[m]\n",
        "          rand_fake = np.array(np.transpose(rand_fake, (1,2,0)))\n",
        "          rand_fake = cv2.normalize(rand_fake, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "          rand_fake = (np.array(rand_fake*255)).astype(np.uint8)\n",
        "          # rand_fake = Image.fromarray(rand_fake)\n",
        "      #save reconstructed images\n",
        "          fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 4), sharex=True, sharey=True)\n",
        "          ax = axes.ravel()\n",
        "\n",
        "          ax[0].imshow(rimg)\n",
        "          ax[0].set_title('real image')\n",
        "\n",
        "          ax[1].imshow(fimg)\n",
        "          ax[1].set_title('reconstructed image')\n",
        "\n",
        "          ax[2].imshow(rand_fake)\n",
        "          ax[2].set_title('reconstructed random image')\n",
        "\n",
        "          plt.tight_layout()\n",
        "          plt.show()\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.savefig(\"/content/drive/MyDrive/thesis/results/digits/reconstructed_img%d.png\"%s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GQKbvjOvdX7"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(real_A[1])\n",
        "# realb = real_test_one.cpu().detach().numpy()\n",
        "realb_new = np.array(np.transpose(real_test_one[20], (1,2,0)))\n",
        "realb_new = cv2.normalize(realb_new, None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "# plt.imshow((realb_new*255).astype(np.uint8) , cmap = \"gray\")\n",
        "patch_imgs_rgb[6020] = cv2.normalize(patch_imgs_rgb[6020], None, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpJGqIRzcSSQ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from SSIM_PIL import compare_ssim\n",
        "from PIL import Image\n",
        "from sklearn.metrics import jaccard_score\n",
        "k = 0\n",
        "s = 0\n",
        "e = 50\n",
        "fakex = []\n",
        "realx = []\n",
        "i = 0\n",
        "SSIM_rec = np.array([])\n",
        "SSIM_Random = np.array([])\n",
        "value_list = np.array([])\n",
        "similarity_array = np.array([])\n",
        "value_list_random = np.array([])\n",
        "# my_rho = np.corrcoef(x_simple, y_simple)************************************************ COrrelation Coefficient\n",
        "h = 0\n",
        "# for i in range(0,5):\n",
        "for j, batch in enumerate(val_dataloader):\n",
        "  if j == 0:\n",
        "      plt.figure()\n",
        "      real_A = batch[\"B\"].type(Tensor)#contours\n",
        "      real_B = batch[\"A\"].type(Tensor)#real images\n",
        "      fake_B = generator(real_A, test_semantic_vec[h:h+50]) #reconstructed images\n",
        "      fake_B = fake_B.cpu().data\n",
        "      fake_B = np.asarray(fake_B)\n",
        "      real_test_one = fake_B\n",
        "      real_B = real_B.cpu().data\n",
        "      # real_b = RGB_test.cpu().data\n",
        "      # real_B = np.asarray(real_B)\n",
        "      fakex = fake_B\n",
        "      realx = real_B\n",
        "      h = h + 50\n",
        "      if h >= 100:\n",
        "        break\n",
        "      for i in range(50):\n",
        "          v = i+h-50\n",
        "          print('**********%d*********'%v)\n",
        "\n",
        "        #reconstructed image\n",
        "          # fimg = fakex[i]\n",
        "          fimg = fake_B[i]\n",
        "          fimg = 0.33 * fimg[0]+ 0.33* fimg[1]+ 0.33*fimg[2]\n",
        "          # fimg[fimg < 0] = 0\n",
        "          # fimg = fimg[:, ::-1]\n",
        "          fimg = fimg.reshape(256, 256) * 255\n",
        "\n",
        "        #real image\n",
        "          rimg = realx[i]\n",
        "          # rimg = RGB_test[i]\n",
        "          rimg = 0.3 * rimg[0]+0.59 * rimg[1]+0.11*rimg[2]\n",
        "          rimg[rimg < 0] = 0\n",
        "          # rimg = rimg[:, ::-1]\n",
        "          rimg = rimg.reshape(256, 256) * 255\n",
        "\n",
        "        #random reconstructed image\n",
        "          m = random.randint(0,49)\n",
        "          while m == i :\n",
        "            m = random.randint(0,49)\n",
        "          # print(fimg.shape)\n",
        "          rand_fake = fake_B[m]\n",
        "          rand_fake = 0.3 * rand_fake[0]+0.59 * rand_fake[1]+0.11*rand_fake[2]\n",
        "          rand_fake[rand_fake < 0] = 0\n",
        "          # rand_fake = rand_fake[:, ::-1]\n",
        "          rand_fake = rand_fake.reshape(256, 256) * 255\n",
        "\n",
        "          # for k in range(256):\n",
        "          #   for j in range(256):\n",
        "          #     if rimg[k][j] <=0:\n",
        "          #       rimg[k][j] = 1\n",
        "          #     else:\n",
        "          #       rimg[k][j] = 0\n",
        "\n",
        "          # for k in range(256):\n",
        "          #   for j in range(256):\n",
        "          #     if rimg[k][j] <= (rimg.max())/2:\n",
        "          #       rimg[k][j] = 0\n",
        "          #     else:\n",
        "          #       rimg[k][j] = 1\n",
        "\n",
        "        # #binarization reconstructed image\n",
        "        #   for k in range(256):\n",
        "        #     for j in range(256):\n",
        "        #       if fimg[k][j] <= (fimg.max())/2:\n",
        "        #         fimg[k][j] = 0\n",
        "        #       else:\n",
        "        #         fimg[k][j] = 1\n",
        "\n",
        "        # #binarization Random reconstructed image\n",
        "        #   for k in range(256):\n",
        "        #     for j in range(256):\n",
        "        #       if rand_fake[k][j] <=  (rand_fake.max())/2:\n",
        "        #         rand_fake[k][j] = 0\n",
        "        #       else:\n",
        "        #         rand_fake[k][j] = 1\n",
        "\n",
        "          im = fimg\n",
        "          im = (np.array(im)).astype(np.uint8)\n",
        "          im = Image.fromarray(im)\n",
        "          im = im.convert('RGB')\n",
        "          real_test = im\n",
        "          # im = cv2.multiply(im * patch_imgs_rgb[6000+i])#**********************\n",
        "\n",
        "          rimg = (np.array(rimg)).astype(np.uint8)\n",
        "          raw_img = Image.fromarray(rimg)\n",
        "          raw_img = raw_img.convert('RGB')\n",
        "          raw_imgs = raw_img\n",
        "          randimg = rand_fake\n",
        "          randimg = (np.array(randimg)).astype(np.uint8)\n",
        "          randimg = Image.fromarray(randimg)\n",
        "          randimg = randimg.convert('RGB')\n",
        "\n",
        "\n",
        "          target = Image.new('RGB', (256 * 2, 256))\n",
        "          target.paste(raw_img, (0, 0, 256, 256))\n",
        "          target.paste(im, (256, 0, 512, 256))\n",
        "          target = target.resize((512, 256), Image.ANTIALIAS)\n",
        "          target = target.convert('L')\n",
        "          target = np.asarray(target)\n",
        "\n",
        "      #save reconstructed images\n",
        "          # print(rimg.min())\n",
        "          # print(rimg.max())\n",
        "          # print(fimg.min())\n",
        "          # print(fimg.max())\n",
        "          im.save('/content/drive/MyDrive/thesis/reconstructed/%d.jpg' % i)\n",
        "          ssim_noise, ssim_cons = ssim_function(rimg,fimg, rand_fake)\n",
        "          SSIM_rec = np.append(SSIM_rec,ssim_noise)\n",
        "          SSIM_Random = np.append(SSIM_Random,ssim_cons)\n",
        "\n",
        "          # similarity = jaccard_score(rimg, fimg, average=\"micro\")\n",
        "          # similarity_array = np.append(similarity_array, similarity)\n",
        "          print(\"new Value for ssim\")\n",
        "          value = compare_ssim(raw_img, im)\n",
        "          value_list = np.append(value_list, value)\n",
        "          print(value)\n",
        "          # value_random = compare_ssim(raw_img, randimg)\n",
        "          # value_list_random = np.append(value_list_random, value_random)\n",
        "          # print(value_random)\n",
        "          ax = plt.subplot(5, 10, i+1)\n",
        "          plt.imshow(np.fliplr(target), cmap='hot')\n",
        "          ax.get_xaxis().set_visible(False)\n",
        "          ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.savefig(\"/content/drive/MyDrive/thesis/results/digits/reconstructed_img%d.png\"%s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGfUH5LlA_mM"
      },
      "outputs": [],
      "source": [
        "print(sum(value_list/50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UE97SXjGfjn"
      },
      "outputs": [],
      "source": [
        "print(sum(value_list_random)/50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQD9Nr2tysa"
      },
      "source": [
        "# **clipping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO7w2sqnWHL-"
      },
      "outputs": [],
      "source": [
        "realb_new = np.array(np.transpose(real_test_one[20], (1,2,0)))\n",
        "print(realb_new.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd9b5CLdUh-3"
      },
      "outputs": [],
      "source": [
        "multi_a = patch_imgs_rgb[6020] * realb_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzEe68TwUnOU"
      },
      "outputs": [],
      "source": [
        "plt.imshow(multi_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOq8zQPYtxRk"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.transpose(real_test_one[1], (1,2,0)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fGHlHDhkOScz",
        "ciUD5-14Oa6k",
        "KmKwQ3nIOnZA",
        "UJKdncjfHrHR",
        "Nqc0Cxr0adxr",
        "QdpiUMKzkV3A",
        "CarAF5lUPUEk",
        "5mLLjxS2anZk",
        "f-ftJF5Pp50S",
        "CMvsJYFM_cgr",
        "pVYOUcyIxVx9",
        "n9wY-rK_aWWF",
        "Ku3Rsa4eRCjs",
        "Yh-p8CZo8As9",
        "JIJKBG93zTDF",
        "Ss1fgvEYUtO7",
        "DoW4H2DcYBzT"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}